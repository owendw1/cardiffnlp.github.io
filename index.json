[{"authors":null,"categories":null,"content":"","date":1680181200,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1680181200,"objectID":"9c6e002dee084707fd173d913c1fda03","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"","tags":null,"title":"Jose Camacho-Collados","type":"authors"},{"authors":null,"categories":null,"content":"","date":1656374400,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1656374400,"objectID":"606c406a7bc2a92c197d4f2c2f8c8a48","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"","tags":null,"title":"Steven Schockaert","type":"authors"},{"authors":null,"categories":null,"content":"","date":1672531200,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1676388905,"objectID":"c0c8affbaaccdb608bac4ae56d20e641","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"","tags":null,"title":"Luis Espinosa-Anke","type":"authors"},{"authors":null,"categories":null,"content":"I am a Lecturer (~Assistant Professor) at the School of Computer Science and Informatics at Cardiff University. My research focuses on technologies that apply Artificial Intelligence for information accessibility. In particular, my work employs Natural Language Processing approaches to facilitate reading and understanding. I am especially interested in studying the real capabilities of systems for several Natural Language Generation tasks, such as Text Simplification, Summarisation and Machine Translation. In order to do that, my collaborators and I create language resources, design evaluation methodologies or metrics, and implement models using machine learning techniques.\n","date":1669852800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1676384573,"objectID":"d8ca3b447b3a5205f254f36debdacdbc","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"I am a Lecturer (~Assistant Professor) at the School of Computer Science and Informatics at Cardiff University. My research focuses on technologies that apply Artificial Intelligence for information accessibility. In particular, my work employs Natural Language Processing approaches to facilitate reading and understanding.","tags":null,"title":"Fernando Alva-Manchego","type":"authors"},{"authors":null,"categories":null,"content":"","date":1672531200,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1676388903,"objectID":"90a6edfb94d86456185488e33ef0aef0","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"","tags":null,"title":"Alun Preece","type":"authors"},{"authors":null,"categories":null,"content":"","date":1678971600,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1678971600,"objectID":"2401a5c82a288c11dbdfca9efb48b84a","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"","tags":null,"title":"Yi Zhou (Jodie)","type":"authors"},{"authors":null,"categories":null,"content":"","date":1672531200,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1676388902,"objectID":"1926fae0125b60e50e490b27f46c3ea0","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"","tags":null,"title":"David Owen","type":"authors"},{"authors":null,"categories":null,"content":"","date":1672531200,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1676388905,"objectID":"29c8cb00b60387b68bccd84ed183d80b","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"","tags":null,"title":"Dimosthenis Antypas","type":"authors"},{"authors":null,"categories":null,"content":"","date":1669852800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1676388903,"objectID":"da850f34cf647685ccfa1c552326c597","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"","tags":null,"title":"Aleks Edwards","type":"authors"},{"authors":null,"categories":null,"content":"","date":1669852800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1676388905,"objectID":"72ecdb0844c4be1874aa05ad177af927","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"","tags":null,"title":"Asahi Ushio","type":"authors"},{"authors":null,"categories":null,"content":"","date":1669852800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1676388905,"objectID":"16f06dda8577b464df992c402eac30f0","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"","tags":null,"title":"Daniel Loureiro","type":"authors"},{"authors":null,"categories":null,"content":"","date":1669852800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1676388903,"objectID":"ac53bb7e1d6a25a603fb592dcc2e7bf1","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"","tags":null,"title":"H√©l√®ne de Ribaupierre","type":"authors"},{"authors":null,"categories":null,"content":"","date":1669852800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1676388905,"objectID":"3ec3edabfc05919ce44c53380e47a247","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"","tags":null,"title":"Joanne Boisson","type":"authors"},{"authors":null,"categories":null,"content":"","date":1669852800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1676388905,"objectID":"fe9e667a3de8d475cc27d1b89bc6037a","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"","tags":null,"title":"Kiamehr Rezaee","type":"authors"},{"authors":null,"categories":null,"content":"","date":1662642e3,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1662642e3,"objectID":"abcfbb49f2db74418f4cb64e1223c737","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"","tags":null,"title":"Zara Siddique","type":"authors"},{"authors":null,"categories":null,"content":"","date":1657026e3,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1657026e3,"objectID":"89d4d8e3bdb50739c3059358e3326885","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"","tags":null,"title":"Carla P√©rez-Almendros","type":"authors"},{"authors":null,"categories":null,"content":"","date":1657026e3,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1676388905,"objectID":"f16a4a8d4349b1e10e013ca287d18cb8","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"","tags":null,"title":"Mark Anderson","type":"authors"},{"authors":null,"categories":null,"content":"","date":1637845200,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1637845200,"objectID":"246173462a570cf4be177537beecdcbf","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"","tags":null,"title":"Amit Gajbhiye","type":"authors"},{"authors":null,"categories":null,"content":"","date":1635724800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1635724800,"objectID":"739e885d6073c46daf848800e98a4542","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"","tags":null,"title":"Federico Liberatore","type":"authors"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"e816e0e9b35c2db355832c2bd934ee9c","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"","tags":null,"title":"Andreas Artemiou","type":"authors"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"94bee0524ce2b206167bb320e8b11588","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"","tags":null,"title":"Hiroyuki Kido","type":"authors"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"0019a2e0630ad5daae4c2f069b4633ff","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"","tags":null,"title":"Hsuvas Borkakoty","type":"authors"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"70779bb1ba33aa89e5337f459632b072","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"","tags":null,"title":"Israa Alghanmi","type":"authors"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"7397a999909d9561cdba3354606b364a","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"","tags":null,"title":"Matthew Powell","type":"authors"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"8b8634e50d98554a02b9289dafd9dfed","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"","tags":null,"title":"Nurul Ariyani","type":"authors"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"a735c85e0881dc1cc9dbf8388683d94c","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"","tags":null,"title":"Usashi Chatterjee","type":"authors"},{"authors":["Jose Camacho-Collados"],"categories":null,"content":"","date":1680181200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1680181200,"objectID":"6450ff7d95884803b1a872f8e00b5705","permalink":"https://cardiffnlp.github.io/event/2023-03-30/","publishdate":"2022-03-22T00:00:00Z","relpermalink":"/event/2023-03-30/","section":"event","summary":"Discussion around impact of technology powered by large language models in NLP research","tags":[],"title":"Discussion: \"Impact of ChatGPT on NLP research\"","type":"event"},{"authors":["Jose Camacho-Collados"],"categories":null,"content":"Invited Speaker: Verna Dankers (University of Edinburgh)\nThe talk discusses experiments from the following two articles:\nDankers, V., Bruni, E., \u0026amp; Hupkes, D. (2022, May). The Paradox of the Compositionality of Natural Language: A Neural Machine Translation Case Study. In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers) (pp. 4154-4175). Dankers, V., Lucas, C., \u0026amp; Titov, I. (2022, May). Can Transformer be Too Compositional? Analysing Idiom Processing in Neural Machine Translation. In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers) (pp. 3608-3626). ","date":1679576400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1679576400,"objectID":"369cfff03dd48af7e71cfa86572149ee","permalink":"https://cardiffnlp.github.io/event/2023-03-23/","publishdate":"2022-03-22T00:00:00Z","relpermalink":"/event/2023-03-23/","section":"event","summary":"Talk by [Verna Dankers](https://www.vernadankers.com/) (University of Edinburgh)","tags":[],"title":"Seminar: \"Idiom Processing in Transformer, a Translation Case Study\"","type":"event"},{"authors":["Yi Zhou (Jodie)"],"categories":null,"content":"Invited Speaker: Yi Zhou (Cardiff University - COMSC)\n","date":1678971600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1678971600,"objectID":"af8b626ab93919112512722c3214f532","permalink":"https://cardiffnlp.github.io/event/2023-03-16/","publishdate":"2022-03-15T00:00:00Z","relpermalink":"/event/2023-03-16/","section":"event","summary":"Talk by [Yi Zhou](https://jodiechou.github.io/) (Cardiff University - COMSC)","tags":[],"title":"Seminar: \"Representation Learning for Word Senses\"","type":"event"},{"authors":["Jose Camacho-Collados"],"categories":null,"content":"Invited Speaker: Alon Samuel and Chris Bowdon (Polecat)\nPolecat is a leading reputational intelligence company that helps companies influence their corporate reputation using real-time textual news sources and social media.\n","date":1677157200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1677157200,"objectID":"18c45a19f0a94d2022ff573a747a2cec","permalink":"https://cardiffnlp.github.io/event/2023-02-23/","publishdate":"2022-02-23T00:00:00Z","relpermalink":"/event/2023-02-23/","section":"event","summary":"Talk by [Alon Samuel ](https://www.linkedin.com/in/alon-samuel-664b8891/) and [Chris Bowdon](https://www.linkedin.com/in/chris-bowdon-657714146/) ([Polecat](https://polecat.com/))","tags":[],"title":"Seminar: \"Polecat's NLP projects\"","type":"event"},{"authors":["Jose Camacho-Collados"],"categories":null,"content":"Invited Speaker: Hang Dong\nReferences:\n[1] Dong, H., Falis, M., Whiteley, W., Alex, B., Matterson, J., Ji, S., ‚Ä¶ \u0026amp; Wu, H. (2022). Automated clinical coding: what, why, and where we are?. npj digital medicine, 5(1), 159. https://doi.org/10.1038/s41746-022-00705-7\n[2] Dong, H., Su√°rez-Paniagua, V., Whiteley, W., \u0026amp; Wu, H. (2021). Explainable automated coding of clinical notes using hierarchical label-wise attention networks and label embedding initialisation. Journal of Biomedical Informatics, 116, 103728. https://arxiv.org/abs/2010.15728\n","date":1676552400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1676552400,"objectID":"f89e7164fe9833192b88152fd8da2457","permalink":"https://cardiffnlp.github.io/event/2023-02-16/","publishdate":"2022-11-16T00:00:00Z","relpermalink":"/event/2023-02-16/","section":"event","summary":"Talk by [Hang Dong](https://scholar.google.com/citations?user=yWs0LD8AAAAJ\u0026hl=en) (University of Oxford)","tags":[],"title":"Seminar: \"Associating Texts with Knowledge Graphs\"","type":"event"},{"authors":["Jose Camacho-Collados"],"categories":null,"content":"Invited Speaker: Nikos Aletras\n","date":1675947600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1675947600,"objectID":"f96b3335d21172b608dbce7f72704623","permalink":"https://cardiffnlp.github.io/event/2023-02-09/","publishdate":"2022-11-16T00:00:00Z","relpermalink":"/event/2023-02-09/","section":"event","summary":"Talk by [Nikos Aletras](https://nikosaletras.com/) (University of Sheffield)","tags":[],"title":"Seminar: \"Towards compute efficient large language models\"","type":"event"},{"authors":["Jose Camacho-Collados"],"categories":null,"content":"Invited Speaker: Nedjma Ousidhoum\n","date":1674738e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1674738e3,"objectID":"f0386993153ffde349191591549c89c3","permalink":"https://cardiffnlp.github.io/event/2023-01-26/","publishdate":"2023-01-23T00:00:00Z","relpermalink":"/event/2023-01-26/","section":"event","summary":"Talk by [Nedjma Ousidhoum](https://nedjmaou.github.io/) (University of Cambridge)","tags":[],"title":"Seminar: \"What Is Needed Vs What is Built in NLP: Toxic Language Detection and Automated Fact-checking Models As Use Cases\"","type":"event"},{"authors":["David Owen","Dimosthenis Antypas","Athanasios Hassoulas","Antonio Pardinas","Luis Espinosa-Anke","Jose Camacho-Collados"],"categories":[],"content":"","date":1672531200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1676388902,"objectID":"d28cbd1068190efe1040696d909e52b3","permalink":"https://cardiffnlp.github.io/publication/owen-2023-detecting/","publishdate":"2023-02-14T15:35:02.368559Z","relpermalink":"/publication/owen-2023-detecting/","section":"publication","summary":"","tags":[],"title":"Detecting depression in users of online forums: enabling early healthcare intervention using language models","type":"publication"},{"authors":["Dimosthenis Antypas","Alun Preece","Jose Camacho-Collados"],"categories":[],"content":"","date":1672531200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1676388902,"objectID":"aaeefe0f0a0c98192836df55a0ab3792","permalink":"https://cardiffnlp.github.io/publication/antypas-2023-negativity/","publishdate":"2023-02-14T15:35:02.628713Z","relpermalink":"/publication/antypas-2023-negativity/","section":"publication","summary":"","tags":[],"title":"Negativity spreads faster: A large-scale multilingual twitter analysis on the role of sentiment in political communication","type":"publication"},{"authors":["Jose Camacho-Collados"],"categories":null,"content":"Invited Speaker: Diana Contreras Mojica\n","date":1669899600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1669899600,"objectID":"02bb66273e37958d72979d4fafd68731","permalink":"https://cardiffnlp.github.io/event/2022-12-01/","publishdate":"2022-11-16T00:00:00Z","relpermalink":"/event/2022-12-01/","section":"event","summary":"Talk by [Diana Contreras Mojica](https://www.cardiff.ac.uk/people/view/2534179-Contreras-Mojica-Diana) (Cardiff University - EARTH)","tags":[],"title":"Seminar: \"Social Media and Crowdsourcing Platforms in Disaster Management\"","type":"event"},{"authors":["Laura V√°squez-Rodrƒ±ÃÅguez","Pedro-Manuel Cuenca-Jim√©nez","Sergio Morales-Esquivel","Fernando Alva-Manchego"],"categories":[],"content":"","date":1669852800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1676384572,"objectID":"7de54f9a19de14a1e9653a222821755d","permalink":"https://cardiffnlp.github.io/publication/vasquez-rodriguez-etal-2022-benchmark/","publishdate":"2023-02-14T14:22:52.486936Z","relpermalink":"/publication/vasquez-rodriguez-etal-2022-benchmark/","section":"publication","summary":"We release a new benchmark for Automated Readability Assessment (ARA) of texts in Spanish. We combined existing corpora with suitable texts collected from the Web, thus creating the largest available dataset for ARA of Spanish texts. All data was pre-processed and categorised to allow experimenting with ARA models that make predictions at two (simple and complex) or three (basic, intermediate, and advanced) readability levels, and at two text granularities (paragraphs and sentences). An analysis based on readability indices shows that our proposed datasets groupings are suitable for their designated readability level. We use our benchmark to train neural ARA models based on BERT in zero-shot, few-shot, and cross-lingual settings. Results show that either a monolingual or multilingual pre-trained model can achieve good results when fine-tuned in language-specific data. In addition, all mod- els decrease their performance when predicting three classes instead of two, showing opportunities for the development of better ARA models for Spanish with existing resources.","tags":[],"title":"A Benchmark for Neural Readability Assessment of Texts in Spanish","type":"publication"},{"authors":["Asahi Ushio","Fernando Alva-Manchego","Jose Camacho-Collados"],"categories":[],"content":"","date":1669852800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1676384572,"objectID":"73d7ecb137ff809211db7acf61c0452f","permalink":"https://cardiffnlp.github.io/publication/ushio-etal-2022-generative/","publishdate":"2023-02-14T14:22:51.86905Z","relpermalink":"/publication/ushio-etal-2022-generative/","section":"publication","summary":"Powerful generative models have led to recent progress in question generation (QG). However, it is difficult to measure advances in QG research since there are no standardized resources that allow a uniform comparison among approaches. In this paper, we introduce QG-Bench, a multilingual and multidomain benchmark for QG that unifies existing question answering datasets by converting them to a standard QG setting. It includes general-purpose datasets such as SQuAD for English, datasets from ten domains and two styles, as well as datasets in eight different languages. Using QG-Bench as a reference, we perform an extensive analysis of the capabilities of language models for the task. First, we propose robust QG baselines based on fine-tuning generative language models. Then, we complement automatic evaluation based on standard metrics with an extensive manual evaluation, which in turn sheds light on the difficulty of evaluating QG models. Finally, we analyse both the domain adaptability of these models as well as the effectiveness of multilingual models in languages other than English.QG-Bench is released along with the fine-tuned models presented in the paper (https://github.com/asahi417/lm-question-generation), which are also available as a demo (https://autoqg.net/).","tags":[],"title":"Generative Language Models for Paragraph-Level Question Generation","type":"publication"},{"authors":["Aleks Edwards","Asahi Ushio","Jose Camacho-Collados","H√©l√®ne de Ribaupierre","Alun Preece"],"categories":[],"content":"","date":1669852800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1676388903,"objectID":"37fc5ea158088a0aa02c5a38556562d8","permalink":"https://cardiffnlp.github.io/publication/edwards-etal-2022-guiding/","publishdate":"2023-02-14T15:35:03.124633Z","relpermalink":"/publication/edwards-etal-2022-guiding/","section":"publication","summary":"Data augmentation techniques are widely used for enhancing the performance of machine learning models by tackling class imbalance issues and data sparsity. State-of-the-art generative language models have been shown to provide significant gains across different NLP tasks. However, their applicability to data augmentation for text classification tasks in few-shot settings have not been fully explored, especially for specialised domains. In this paper, we leverage GPT-2 (Radford et al, 2019) for generating artificial training instances in order to improve classification performance. Our aim is to analyse the impact the selection process of seed training examples has over the quality of GPT-generated samples and consequently the classifier performance. We propose a human-in-the-loop approach for selecting seed samples. Further, we compare the approach to other seed selection strategies that exploit the characteristics of specialised domains such as human-created class hierarchical structure and the presence of noun phrases. Our results show that fine-tuning GPT-2 in a handful of label instances leads to consistent classification improvements and outperform competitive baselines. The seed selection strategies developed in this work lead to significant improvements over random seed selection for specialised domains. We show that guiding text generation through domain expert selection can lead to further improvements, which opens up interesting research avenues for combining generative models and active learning.","tags":[],"title":"Guiding Generative Language Models for Data Augmentation in Few-Shot Text Classification","type":"publication"},{"authors":["Jeffri Murrugarra-Llerena","Fernando Alva-Manchego","Nils Murrugarra-Llerena"],"categories":[],"content":"","date":1669852800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1676384572,"objectID":"ca38b8ab768b662b62593735345829ac","permalink":"https://cardiffnlp.github.io/publication/murrugarra-llerena-etal-2022-improving/","publishdate":"2023-02-14T14:22:52.254197Z","relpermalink":"/publication/murrugarra-llerena-etal-2022-improving/","section":"publication","summary":"We propose an approach for comparing curricula of study programs in higher education. Pre-trained word embeddings are fine-tuned in a study program classification task, where each curriculum is represented by the names and content of its courses. By combining metric learning with a novel course-guided attention mechanism, our method obtains more accurate curriculum representations than strong baselines. Experiments on a new dataset with curricula of computing programs demonstrate the intuitive power of our approach via attention weights, topic modeling, and embeddings visualizations. We also present a use case comparing computing curricula from USA and Latin America to showcase the capabilities of our improved embeddings representations.","tags":[],"title":"Improving Embeddings Representations for Comparing Higher Education Curricula: A Use Case in Computing","type":"publication"},{"authors":["Kiamehr Rezaee","Jose Camacho-Collados"],"categories":[],"content":"","date":1669852800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1676388904,"objectID":"cf7fccaf14866011d510b08a684a1ff9","permalink":"https://cardiffnlp.github.io/publication/rezaee-camacho-collados-2022-probing/","publishdate":"2023-02-14T15:35:03.693178Z","relpermalink":"/publication/rezaee-camacho-collados-2022-probing/","section":"publication","summary":"Understanding relational knowledge plays an integral part in natural language comprehension. When it comes to pre-trained language models (PLM), prior work has been focusing on probing relational knowledge this by filling the blanks in pre-defined prompts such as ``The capital of France is ---''. However, these probes may be affected by the co-occurrence of target relation words and entities (e.g. ``capital‚Ä≥, ``France‚Ä≥ and ``Paris‚Ä≥) in the pre-training corpus. In this work, we extend these probing methodologies leveraging analogical proportions as a proxy to probe relational knowledge in transformer-based PLMs without directly presenting the desired relation. In particular, we analysed the ability of PLMs to understand (1) the directionality of a given relation (e.g. Paris-France is not the same as France-Paris); (2) the ability to distinguish types on a given relation (both France and Japan are countries); and (3) the relation itself (Paris is the capital of France, but not Rome). Our results show how PLMs are extremely accurate at (1) and (2), but have clear room for improvement for (3). To better understand the reasons behind this behaviour and mistakes made by PLMs, we provide an extended quantitative analysis based on relevant factors such as frequency.","tags":[],"title":"Probing Relational Knowledge in Language Models via Word Analogies","type":"publication"},{"authors":["Jose Camacho-Collados","Kiamehr Rezaee","Talayeh Riahi","Asahi Ushio","Daniel Loureiro","Dimosthenis Antypas","Joanne Boisson","Luis Espinosa-Anke","Fangyu Liu","Eugenio Martƒ±ÃÅnez C√°mara"],"categories":[],"content":"","date":1669852800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1676388905,"objectID":"797fb0fe2f8af86df4ba8a216fcdabfc","permalink":"https://cardiffnlp.github.io/publication/camacho-collados-etal-2022-tweetnlp/","publishdate":"2023-02-14T15:35:05.213302Z","relpermalink":"/publication/camacho-collados-etal-2022-tweetnlp/","section":"publication","summary":"In this paper we present TweetNLP, an integrated platform for Natural Language Processing (NLP) in social media. TweetNLP supports a diverse set of NLP tasks, including generic focus areas such as sentiment analysis and named entity recognition, as well as social media-specific tasks such as emoji prediction and offensive language identification. Task-specific systems are powered by reasonably-sized Transformer-based language models specialized on social media text (in particular, Twitter) which can be run without the need for dedicated hardware or cloud services. The main contributions of TweetNLP are: (1) an integrated Python library for a modern toolkit supporting social media analysis using our various task-specific models adapted to the social domain; (2) an interactive online demo for codeless experimentation using our models; and (3) a tutorial covering a wide variety of typical social media applications.","tags":[],"title":"TweetNLP: Cutting-Edge Natural Language Processing for Social Media","type":"publication"},{"authors":["Asahi Ushio","Francesco Barbieri","Vitor Sousa","Leonardo Neves","Jose Camacho-Collados"],"categories":[],"content":"","date":1667260800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1676388903,"objectID":"aa8d71ed4c44fe024e9b44ead0be58d4","permalink":"https://cardiffnlp.github.io/publication/ushio-etal-2022-named/","publishdate":"2023-02-14T15:35:03.439396Z","relpermalink":"/publication/ushio-etal-2022-named/","section":"publication","summary":"Recent progress in language model pre-training has led to important improvements in Named Entity Recognition (NER). Nonetheless, this progress has been mainly tested in well-formatted documents such as news, Wikipedia, or scientific articles. In social media the landscape is different, in which it adds another layer of complexity due to its noisy and dynamic nature. In this paper, we focus on NER in Twitter, one of the largest social media platforms, and construct a new NER dataset, TweetNER7, which contains seven entity types annotated over 11,382 tweets from September 2019 to August 2021. The dataset was constructed by carefully distributing the tweets over time and taking representative trends as a basis. Along with the dataset, we provide a set of language model baselines and perform an analysis on the language model performance on the task, especially analyzing the impact of different time periods. In particular, we focus on three important temporal aspects in our analysis: short-term degradation of NER models over time, strategies to fine-tune a language model over different periods, and self-labeling as an alternative to lack of recently-labeled data. TweetNER7 is released publicly (https://huggingface.co/datasets/tner/tweetner7) along with the models fine-tuned on it (NER models have been integrated into TweetNLP and can be found at https://github.com/asahi417/tner/tree/master/examples/tweetner7_paper).","tags":[],"title":"Named Entity Recognition in Twitter: A Dataset and Analysis on Short-Term Temporal Shifts","type":"publication"},{"authors":["Martina Miliani","Serena Auriemma","Fernando Alva-Manchego","Alessandro Lenci"],"categories":[],"content":"","date":1667260800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1676384573,"objectID":"4c5a569046dcd8de27af62ea996a49df","permalink":"https://cardiffnlp.github.io/publication/miliani-etal-2022-neural/","publishdate":"2023-02-14T14:22:52.773322Z","relpermalink":"/publication/miliani-etal-2022-neural/","section":"publication","summary":"Automatic Readability Assessment aims at assigning a complexity level to a given text, which could help improve the accessibility to information in specific domains, such as the administrative one. In this paper, we investigate the behavior of a Neural Pairwise Ranking Model (NPRM) for sentence-level readability assessment of Italian administrative texts. To deal with data scarcity, we experiment with cross-lingual, cross- and in-domain approaches, and test our models on Admin-It, a new parallel corpus in the Italian administrative language, containing sentences simplified using three different rewriting strategies. We show that NPRMs are effective in zero-shot scenarios (~0.78 ranking accuracy), especially with ranking pairs containing simplifications produced by overall rewriting at the sentence-level, and that the best results are obtained by adding in-domain data (achieving perfect performance for such sentence pairs). Finally, we investigate where NPRMs failed, showing that the characteristics of the training data, rather than its size, have a bigger effect on a model‚Ä≤s performance.","tags":[],"title":"Neural Readability Pairwise Ranking for Sentences in Italian Administrative Language","type":"publication"},{"authors":null,"categories":null,"content":"üìÖ 16th and 17th Nov, 10am - 5pm\nüìç Tramshed Tech\nSponsored by AMPLYFI\nAt this 2-day hackathon you‚Äôll enter the fascinating world of Natural Language Processing. Dig into real-world text data, generate insights, and present your findings to academic and industry experts.\nFREE food and drinks on both days üçï PRIZES! ü§ë Networking with potential employers üó£ Form your own team of 3-5 people or we‚Äôll help to find you one! Register here!\n","date":1666224e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1666224e3,"objectID":"bd4eb2b1c06b4821a83f111d42b662fd","permalink":"https://cardiffnlp.github.io/hackathon/","publishdate":"2022-10-20T00:00:00Z","relpermalink":"/hackathon/","section":"","summary":"üìÖ 16th and 17th Nov, 10am - 5pm\nüìç Tramshed Tech\nSponsored by AMPLYFI\nAt this 2-day hackathon you‚Äôll enter the fascinating world of Natural Language Processing. Dig into real-world text data, generate insights, and present your findings to academic and industry experts.","tags":null,"title":"Cardiff NLP Hackathon","type":"page"},{"authors":["Daniel Loureiro"],"categories":null,"content":"Invited Speaker: Daniel Loureiro\nRelated Links:\nCOLING 2022 preprint TempoWiC Shared Task (EvoNLP workshop, EMNLP 2022) ","date":1665666e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1665666e3,"objectID":"e98c267a81e641bc2481b6ceeb60b7c3","permalink":"https://cardiffnlp.github.io/event/2022-10-13/","publishdate":"2022-07-26T00:00:00Z","relpermalink":"/event/2022-10-13/","section":"event","summary":"Talk by [Daniel Loureiro](http://danlou.github.io/) (Cardiff University)","tags":[],"title":"Seminar: \"TempoWiC: An Evaluation Benchmark for Detecting Meaning Shift in Social Media\"","type":"event"},{"authors":["Jose Camacho-Collados"],"categories":null,"content":"Invited Speaker: Nuria Rodr√≠guez Barroso\n","date":1665061200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1665061200,"objectID":"75d57c63b46410645b1f99da0bea0529","permalink":"https://cardiffnlp.github.io/event/2022-10-06/","publishdate":"2022-09-22T00:00:00Z","relpermalink":"/event/2022-10-06/","section":"event","summary":"Talk by [Nuria Rodr√≠guez Barroso](https://scholar.google.com/citations?user=vwb4B_kAAAAJ\u0026hl=en) (Universidad de Granada)","tags":[],"title":"Seminar: \"Federated Learning for Exploiting Annotator Disagreements in NLP\"","type":"event"},{"authors":["Daniel Loureiro","Aminette D‚Ä≤Souza","Areej Nasser Muhajab","Isabella A. White","Gabriel Wong","Luis Espinosa-Anke","Leonardo Neves","Francesco Barbieri","Jose Camacho-Collados"],"categories":[],"content":"","date":1664582400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1676388904,"objectID":"9a83e615930d7619d8c180bea1c90cba","permalink":"https://cardiffnlp.github.io/publication/loureiro-etal-2022-tempowic/","publishdate":"2023-02-14T15:35:04.372963Z","relpermalink":"/publication/loureiro-etal-2022-tempowic/","section":"publication","summary":"Language evolves over time, and word meaning changes accordingly. This is especially true in social media, since its dynamic nature leads to faster semantic shifts, making it challenging for NLP models to deal with new content and trends. However, the number of datasets and models that specifically address the dynamic nature of these social platforms is scarce. To bridge this gap, we present TempoWiC, a new benchmark especially aimed at accelerating research in social media-based meaning shift. Our results show that TempoWiC is a challenging benchmark, even for recently-released language models specialized in social media.","tags":[],"title":"TempoWiC: An Evaluation Benchmark for Detecting Meaning Shift in Social Media","type":"publication"},{"authors":["Dimosthenis Antypas","Asahi Ushio","Jose Camacho-Collados","Vitor Silva","Leonardo Neves","Francesco Barbieri"],"categories":[],"content":"","date":1664582400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1676388904,"objectID":"f650b9451d6f25fbfe626eeaab7c9036","permalink":"https://cardiffnlp.github.io/publication/antypas-etal-2022-twitter/","publishdate":"2023-02-14T15:35:04.017768Z","relpermalink":"/publication/antypas-etal-2022-twitter/","section":"publication","summary":"Social media platforms host discussions about a wide variety of topics that arise everyday. Making sense of all the content and organising it into categories is an arduous task. A common way to deal with this issue is relying on topic modeling, but topics discovered using this technique are difficult to interpret and can differ from corpus to corpus. In this paper, we present a new task based on tweet topic classification and release two associated datasets. Given a wide range of topics covering the most important discussion points in social media, we provide training and testing data from recent time periods that can be used to evaluate tweet classification models. Moreover, we perform a quantitative evaluation and analysis of current general- and domain-specific language models on the task, which provide more insights on the challenges and nature of the task.","tags":[],"title":"Twitter Topic Classification","type":"publication"},{"authors":["Jose Camacho-Collados"],"categories":null,"content":"","date":1664456400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1664456400,"objectID":"0e81c42dbc192c0a2f8a3c4d68ed72b1","permalink":"https://cardiffnlp.github.io/event/2022-09-29/","publishdate":"2022-09-22T00:00:00Z","relpermalink":"/event/2022-09-29/","section":"event","summary":"Talks by authors of papers accepted to COLING 2022","tags":[],"title":"Conference-like Presentations","type":"event"},{"authors":["Jose Camacho-Collados"],"categories":null,"content":"","date":1663851600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1663851600,"objectID":"b58b98e49a242d5782a41b3595672f94","permalink":"https://cardiffnlp.github.io/event/2022-09-22/","publishdate":"2022-09-06T00:00:00Z","relpermalink":"/event/2022-09-22/","section":"event","summary":"","tags":[],"title":"[Internal] Quaterly Group Meeting","type":"event"},{"authors":["Jose Camacho-Collados","Fernando Alva-Manchego"],"categories":null,"content":"The School of Computer Science and Informatics at Cardiff University (Wales, United Kingdom) is now recruiting for 14 posts at the levels of Lecturer (~Assistant Prof) or Senior Lecturer (~Associate Prof) in several areas of Computer Science, including Natural Language Processing (NLP).\nFurther details can be found here:\nLecturer (Teaching \u0026amp; Scholarship) Lecturer (Teaching \u0026amp; Research) Senior Lecturer (Teaching \u0026amp; Scholarship) Senior Lecturer (Teaching \u0026amp; Research) Application Deadline: Friday, 7 October 2022.\n","date":1662681600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1662681600,"objectID":"22469cebb08609c5ad4d265e6b6f8f93","permalink":"https://cardiffnlp.github.io/post/2022-09-09/","publishdate":"2022-09-09T00:00:00Z","relpermalink":"/post/2022-09-09/","section":"post","summary":"The School of Computer Science and Informatics at Cardiff University (Wales, United Kingdom) is now recruiting for 14 posts at the levels of Lecturer (~Assistant Prof) or Senior Lecturer (~Associate Prof) in several areas of Computer Science, including Natural Language Processing (NLP).\n","tags":null,"title":"14 New Lecturer/Senior Lecturer Positions","type":"post"},{"authors":["Jose Camacho-Collados","Zara Siddique"],"categories":null,"content":"","date":1662642e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1662642e3,"objectID":"1c3df7669246973639cb4923b974ea8b","permalink":"https://cardiffnlp.github.io/event/2022-09-08/","publishdate":"2022-08-01T00:00:00Z","relpermalink":"/event/2022-09-08/","section":"event","summary":"","tags":[],"title":"[Internal] Cardiff NLP Hackathon Organisation","type":"event"},{"authors":["Jose Camacho-Collados"],"categories":null,"content":"We are looking for a Research Associate for a UKRI Future Leaders Fellowship project on Natural Language Processing titled ‚ÄúUnsupervised background knowledge for language understanding‚Äù.\nFor an informal discussion about the role, please contact Jose Camacho Collados (Senior Lecturer) ‚Äì camachocolladosj@cardiff.ac.uk.\nApplication Deadline: September 4th\nStart Date: January 2023 (flexible)\n","date":1660176e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1660176e3,"objectID":"3ba6e0cc3e3c259f5ee0946d9a40e07a","permalink":"https://cardiffnlp.github.io/post/2022-08-11/","publishdate":"2022-08-11T00:00:00Z","relpermalink":"/post/2022-08-11/","section":"post","summary":"We are looking for a Research Associate for a UKRI Future Leaders Fellowship project on Natural Language Processing titled ‚ÄúUnsupervised background knowledge for language understanding‚Äù.\n","tags":null,"title":"New Research Associate Position","type":"post"},{"authors":["Jose Camacho-Collados"],"categories":null,"content":"Applications are invited for nine Teaching Associate posts in the School of Computer Science \u0026amp; Informatics at Cardiff University. Posts are available on a part-time (0.5FTE) basis. Part-time posts will be accompanied with the opportunity to also study towards a PhD part-time.\nFor an informal discussion about the role please contact Dr Martin Chorley - ChorleyMJ@cardiff.ac.uk\nApplication Deadline: September 7th\n","date":1660176e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1660176e3,"objectID":"059fd2cb196056682250bfac7e95bc1f","permalink":"https://cardiffnlp.github.io/post/2022-08-12/","publishdate":"2022-08-11T00:00:00Z","relpermalink":"/post/2022-08-12/","section":"post","summary":"Applications are invited for nine Teaching Associate posts in the School of Computer Science \u0026 Informatics at Cardiff University. Posts are available on a part-time (0.5FTE) basis. Part-time posts will be accompanied with the opportunity to also study towards a PhD part-time.\n","tags":null,"title":"New Teaching Associate Position","type":"post"},{"authors":["Carla P√©rez-Almendros","Mark Anderson"],"categories":null,"content":"","date":1657026e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1657026e3,"objectID":"e6882b8f44baba520706d9873901729c","permalink":"https://cardiffnlp.github.io/event/2022-07-05/","publishdate":"2022-06-14T00:00:00Z","relpermalink":"/event/2022-07-05/","section":"event","summary":"Talks by Carla Perez-Almendros (SemEval task) y Mark Anderson (*SEM paper)","tags":[],"title":"Conference-like Presentations","type":"event"},{"authors":["Mark Anderson","Jose Camacho-Collados"],"categories":[],"content":"","date":1656633600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1676388905,"objectID":"2207d4f6617d650d10f2aac5b3be4fea","permalink":"https://cardiffnlp.github.io/publication/anderson-camacho-collados-2022-assessing/","publishdate":"2023-02-14T15:35:05.522801Z","relpermalink":"/publication/anderson-camacho-collados-2022-assessing/","section":"publication","summary":"The increase in performance in NLP due to the prevalence of distributional models and deep learning has brought with it a reciprocal decrease in interpretability. This has spurred a focus on what neural networks learn about natural language with less of a focus on how. Some work has focused on the data used to develop data-driven models, but typically this line of work aims to highlight issues with the data, e.g. highlighting and offsetting harmful biases. This work contributes to the relatively untrodden path of what is required in data for models to capture meaningful representations of natural language. This is entails evaluating how well English and Spanish semantic spaces capture a particular type of relational knowledge, namely the traits associated with concepts (e.g. bananas-yellow), and exploring the role of co-occurrences in this context.","tags":[],"title":"Assessing the Limits of the Distributional Hypothesis in Semantic Spaces: Trait-based Relational Knowledge and the Impact of Co-occurrences","type":"publication"},{"authors":["Joanne Boisson","Jose Camacho-Collados","Luis Espinosa-Anke"],"categories":[],"content":"","date":1656633600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1676388905,"objectID":"1fd557fe97062c8dbfd983367d988d5f","permalink":"https://cardiffnlp.github.io/publication/boisson-etal-2022-cardiffnlp/","publishdate":"2023-02-14T15:35:04.985379Z","relpermalink":"/publication/boisson-etal-2022-cardiffnlp/","section":"publication","summary":"This paper describes the experiments ran for SemEval-2022 Task 2, subtask A, zero-shot and one-shot settings for idiomaticity detection. Our main approach is based on fine-tuning transformer-based language models as a baseline to perform binary classification. Our system, CardiffNLP-Metaphor, ranked 8th and 7th (respectively on zero- and one-shot settings on this task. Our main contribution lies in the extensive evaluation of transformer-based language models and various configurations, showing, among others, the potential of large multilingual models over base monolingual models. Moreover, we analyse the impact of various input parameters, which offer interesting insights on how language models work in practice.","tags":[],"title":"CardiffNLP-Metaphor at SemEval-2022 Task 2: Targeted Fine-tuning of Transformer-based Language Models for Idiomaticity Detection","type":"publication"},{"authors":["Carla P√©rez-Almendros","Luis Espinosa-Anke","Steven Schockaert"],"categories":[],"content":"","date":1656374400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1656374400,"objectID":"dc435b552619b472c38059ee7709fdc4","permalink":"https://cardiffnlp.github.io/project/plc-sharedtask/","publishdate":"2022-06-28T00:00:00Z","relpermalink":"/project/plc-sharedtask/","section":"project","summary":"SemEval 2022 Task 4: Patronizing and Condescending Language Detection","tags":["sharedtask"],"title":"PCL Detection","type":"project"},{"authors":["Daniel Loureiro","Jose Camacho-Collados"],"categories":[],"content":"","date":1656374400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1656374400,"objectID":"089fbb02c0b74abfcaf309a05f045320","permalink":"https://cardiffnlp.github.io/project/tempowic/","publishdate":"2022-06-28T00:00:00Z","relpermalink":"/project/tempowic/","section":"project","summary":"EvoNLP Shared Task: Temporal Meaning Shift","tags":["sharedtask"],"title":"TempoWiC  ","type":"project"},{"authors":["Jose Camacho-Collados","Luis Espinosa-Anke","Daniel Loureiro","Asahi Ushio","Dimosthenis Antypas","Kiamehr Rezaee","Joanne Boisson"],"categories":[],"content":"","date":1656374400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1656374400,"objectID":"83b815ef93dc48277092cb8bfd711e73","permalink":"https://cardiffnlp.github.io/project/tweetnlp/","publishdate":"2022-06-28T00:00:00Z","relpermalink":"/project/tweetnlp/","section":"project","summary":"A website to enable users to use cutting-edge language technologies in social media.","tags":["twitter"],"title":"Tweet   NLP","type":"project"},{"authors":["Jose Camacho-Collados"],"categories":null,"content":"We are looking for a Research Assistant for a UKRI Future Leaders Fellowship project on Natural Language Processing.\nFor an informal discussion about the role, please contact Jose Camacho Collados (Senior Lecturer) ‚Äì camachocolladosj@cardiff.ac.uk.\nApplication Deadline: July 11th\nStart Date: September 2022 or later (flexible)\n","date":1656288e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1656288e3,"objectID":"7a1dd6fea04141125cfd6cd8d0ee3960","permalink":"https://cardiffnlp.github.io/post/2022-06-27/","publishdate":"2022-06-27T00:00:00Z","relpermalink":"/post/2022-06-27/","section":"post","summary":"We are looking for a Research Assistant for a UKRI Future Leaders Fellowship project on Natural Language Processing.\n","tags":null,"title":"New Research Assistant Position","type":"post"},{"authors":["Jose Camacho-Collados"],"categories":null,"content":"","date":1655989200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1655989200,"objectID":"cc19704f1597337d5f706525f53b5486","permalink":"https://cardiffnlp.github.io/event/2022-06-23/","publishdate":"2022-05-11T00:00:00Z","relpermalink":"/event/2022-06-23/","section":"event","summary":"","tags":[],"title":"[Internal] Cardiff NLP Workshop Organisation","type":"event"},{"authors":["Fernando Alva-Manchego"],"categories":null,"content":"Invited Speaker: Sian Gooding\nShort Bio: Sian Gooding is a PhD student at the University of Cambridge Computer Laboratory within the Natural Language and Information Processing group and a visiting researcher at the Language, Computation and Cognition Lab. Her research focuses on readability and text simplification ‚Äì the study of how to automatically adapt text to suit the needs of different audiences.\n","date":1654779600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1654779600,"objectID":"7440384608805a5e7bdc154691feac96","permalink":"https://cardiffnlp.github.io/event/2022-06-09/","publishdate":"2022-04-20T00:00:00Z","relpermalink":"/event/2022-06-09/","section":"event","summary":"Talk by Sian Gooding (University of Cambridge)","tags":[],"title":"Seminar: \"Textual Complexity is in the Eye of the Beholder\" ","type":"event"},{"authors":["Gissella Bejarano","Joe Huamani-Malca","Francisco Cerna-Herrera","Fernando Alva-Manchego","Pablo Rivas"],"categories":[],"content":"","date":1654041600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1676384573,"objectID":"8d78a861b6ac02ccc9342d42454212cf","permalink":"https://cardiffnlp.github.io/publication/bejarano-etal-2022-perusil/","publishdate":"2023-02-14T14:22:53.052484Z","relpermalink":"/publication/bejarano-etal-2022-perusil/","section":"publication","summary":"Video-based datasets for Continuous Sign Language are scarce due to the challenging task of recording videos from native signers and the reduced number of people who can annotate sign language. COVID-19 has evidenced the key role of sign language interpreters in delivering nationwide health messages to deaf communities. In this paper, we present a framework for creating a multi-modal sign language interpretation dataset based on videos and we use it to create the first dataset for Peruvian Sign Language (LSP) interpretation annotated by hearing volunteers who have intermediate knowledge of PSL guided by the video audio. We rely on hearing people to produce a first version of the annotations, which should be reviewed by native signers in the future. Our contributions: i) we design a framework to annotate a sign Language dataset; ii) we release the first annotated LSP multi-modal interpretation dataset (AEC); iii) we evaluate the annotation done by hearing people by training a sign language recognition model. Our model reaches up to 80.3% of accuracy among a minimum of five classes (signs) AEC dataset, and 52.4% in a second dataset. Nevertheless, analysis by subject in the second dataset show variations worth to discuss.","tags":[],"title":"PeruSIL: A Framework to Build a Continuous Peruvian Sign Language Interpretation Dataset","type":"publication"},{"authors":["Matthew Shardlow","Fernando Alva-Manchego"],"categories":[],"content":"","date":1654041600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1676384573,"objectID":"1c32cc95a7f8cb38b522f99e307a89b5","permalink":"https://cardiffnlp.github.io/publication/shardlow-alva-manchego-2022-simple/","publishdate":"2023-02-14T14:22:53.313219Z","relpermalink":"/publication/shardlow-alva-manchego-2022-simple/","section":"publication","summary":"Specialist high-quality information is typically first available in English, and it is written in a language that may be difficult to understand by most readers. While Machine Translation technologies contribute to mitigate the first issue, the translated content will most likely still contain complex language. In order to investigate and address both problems simultaneously, we introduce Simple TICO-19, a new language resource containing manual simplifications of the English and Spanish portions of the TICO-19 corpus for Machine Translation of COVID-19 literature. We provide an in-depth description of the annotation process, which entailed designing an annotation manual and employing four annotators (two native English speakers and two native Spanish speakers) who simplified over 6,000 sentences from the English and Spanish portions of the TICO-19 corpus. We report several statistics on the new dataset, focusing on analysing the improvements in readability from the original texts to their simplified versions. In addition, we propose baseline methodologies for automatically generating the simplifications, translations and joint translation and simplifications contained in our dataset.","tags":[],"title":"Simple TICO-19: A Dataset for Joint Translation and Simplification of COVID-19 Texts","type":"publication"},{"authors":["Fernando Alva-Manchego","Matthew Shardlow"],"categories":[],"content":"","date":1654041600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1676384573,"objectID":"2db14abe62f8511acfcd001ed55fe084","permalink":"https://cardiffnlp.github.io/publication/alva-manchego-shardlow-2022-towards/","publishdate":"2023-02-14T14:22:53.695215Z","relpermalink":"/publication/alva-manchego-shardlow-2022-towards/","section":"publication","summary":"This project investigates the capabilities of Machine Translation models for generating translations at varying levels of readability, focusing on texts related to COVID-19. Whilst it is possible to automatically translate this information, the resulting text may contain specialised terminology, or may be written in a style that is difficult for lay readers to understand. So far, we have collected a new dataset with manual simplifications for English and Spanish sentences in the TICO-19 dataset, as well as implemented baseline pipelines combining Machine Translation and Text Simplification models.","tags":[],"title":"Towards Readability-Controlled Machine Translation of COVID-19 Texts","type":"publication"},{"authors":["Francesco Barbieri","Luis Espinosa-Anke","Jose Camacho-Collados"],"categories":[],"content":"","date":1654041600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1676388903,"objectID":"0a6a3a04ea0a7df001458cc839e37cb2","permalink":"https://cardiffnlp.github.io/publication/barbieri-etal-2022-xlm/","publishdate":"2023-02-14T15:35:02.881403Z","relpermalink":"/publication/barbieri-etal-2022-xlm/","section":"publication","summary":"Language models are ubiquitous in current NLP, and their multilingual capacity has recently attracted considerable attention. However, current analyses have almost exclusively focused on (multilingual variants of) standard benchmarks, and have relied on clean pre-training and task-specific corpora as multilingual signals. In this paper, we introduce XLM-T, a model to train and evaluate multilingual language models in Twitter. In this paper we provide: (1) a new strong multilingual baseline consisting of an XLM-R (Conneau et al. 2020) model pre-trained on millions of tweets in over thirty languages, alongside starter code to subsequently fine-tune on a target task; and (2) a set of unified sentiment analysis Twitter datasets in eight different languages and a XLM-T model trained on this dataset.","tags":[],"title":"XLM-T: Multilingual Language Models in Twitter for Sentiment Analysis and Beyond","type":"publication"},{"authors":["Fernando Alva-Manchego"],"categories":null,"content":"Invited Speaker: Arturo Oncevay\nShort Bio: Arturo Oncevay (he/him) is a PhD candidate at the University of Edinburgh, Scotland. He was a member of the Artificial Intelligence group at the Pontificia Universidad Cat√≥lica del Per√∫ (PUCP, Peru), where he graduated from Informatics Engineering and Masters in Computer Science. His work focuses on low-resource machine translation and in computational typology for NLP, and he likes to support the development of NLP tools for endangered languages spoken in the Amazonia. He has also co-organised the AmericasNLP workshop (NAACL 2021) and shared task on machine translation (NAACL 2021) and speech-to-text translation (in preparation for NeurIPS 2022).\n","date":1652965200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1652965200,"objectID":"1d7210eba4451638e0ee1866a72d5076","permalink":"https://cardiffnlp.github.io/event/2022-05-19/","publishdate":"2022-04-20T00:00:00Z","relpermalink":"/event/2022-05-19/","section":"event","summary":"Talk by Arturo Oncevay (University of Edinburgh)","tags":[],"title":"Seminar: \"Quantifying Synthesis and Fusion and their Impact on Machine Translation\"","type":"event"},{"authors":["Jose Camacho-Collados","Luis Espinosa-Anke"],"categories":null,"content":"","date":1652360400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1652360400,"objectID":"bc0c6516efb7c2690a96bc4794f725af","permalink":"https://cardiffnlp.github.io/event/2022-05-12/","publishdate":"2022-02-18T23:11:09Z","relpermalink":"/event/2022-05-12/","section":"event","summary":"Talk by Jose Camacho-Chollados and Luis Espinosa-Anke","tags":[],"title":"Seminar: \"Language Models for Social Media: Challenges and Applications\"","type":"event"},{"authors":["Fernando Alva-Manchego"],"categories":null,"content":"We are happy to officially announce the 1st Cardiff NLP Summer Workshop on June 30 and July 1!\nThis workshop will be an opportunity for participants to interact and attend talks/tutorials from high-profile NLP researchers from industry and academia.\nRegistration is free. Submit your Expression of Interest by May 30. More information here.\n","date":1652227200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1652227200,"objectID":"8274ef2b4dd01b1348277dfd43e683c1","permalink":"https://cardiffnlp.github.io/post/2022-05-11/","publishdate":"2022-05-11T00:00:00Z","relpermalink":"/post/2022-05-11/","section":"post","summary":"We are happy to officially announce the 1st Cardiff NLP Summer Workshop on June 30 and July 1!\nThis workshop will be an opportunity for participants to interact and attend talks/tutorials from high-profile NLP researchers from industry and academia.","tags":null,"title":"Expressions of Interest for Cardiff NLP Summer Workshop 2022","type":"post"},{"authors":["Daniel Loureiro","Francesco Barbieri","Leonardo Neves","Luis Espinosa-Anke","Jose Camacho-Collados"],"categories":[],"content":"","date":1651363200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1676388904,"objectID":"f139de3782a4ab7a8c213d70fd3999e0","permalink":"https://cardiffnlp.github.io/publication/loureiro-etal-2022-timelms/","publishdate":"2023-02-14T15:35:04.681726Z","relpermalink":"/publication/loureiro-etal-2022-timelms/","section":"publication","summary":"Despite its importance, the time variable has been largely neglected in the NLP and language model literature. In this paper, we present TimeLMs, a set of language models specialized on diachronic Twitter data. We show that a continual learning strategy contributes to enhancing Twitter-based language models‚Ä≤ capacity to deal with future and out-of-distribution tweets, while making them competitive with standardized and more monolithic benchmarks. We also perform a number of qualitative analyses showing how they cope with trends and peaks in activity involving specific named entities or concept drift. TimeLMs is available at github.com/cardiffnlp/timelms.","tags":[],"title":"TimeLMs: Diachronic Language Models from Twitter","type":"publication"},{"authors":["Jose Camacho-Collados"],"categories":null,"content":"","date":1651150800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1651150800,"objectID":"22624287e8c05169a103190393b6279a","permalink":"https://cardiffnlp.github.io/event/2022-04-28/","publishdate":"2022-04-20T00:00:00Z","relpermalink":"/event/2022-04-28/","section":"event","summary":"","tags":[],"title":"[Internal] Cardiff NLP Workshop Organisation","type":"event"},{"authors":["Jose Camacho-Collados"],"categories":null,"content":"","date":1650546e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1650546e3,"objectID":"28c3f7efd9b751e6ddf271f9a8f42d81","permalink":"https://cardiffnlp.github.io/event/2022-04-21/","publishdate":"2022-04-04T00:00:00Z","relpermalink":"/event/2022-04-21/","section":"event","summary":"","tags":[],"title":"[Internal] New NLP PhD/RA Office Allocations","type":"event"},{"authors":["Jose Camacho-Collados"],"categories":null,"content":"","date":1649336400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1649336400,"objectID":"f548ce95a312b60418c859ae31b41e9b","permalink":"https://cardiffnlp.github.io/event/2022-04-07/","publishdate":"2022-03-08T23:11:04Z","relpermalink":"/event/2022-04-07/","section":"event","summary":"","tags":[],"title":"5-minute Presentations","type":"event"},{"authors":["Jose Camacho-Collados"],"categories":null,"content":"Speaker: Thomas Simonini (Machine Learning Engineer at HuggingFace)\nDescription of the Session:\nHow can you show what a Machine Learning model does once it‚Äôs trained?\nIn this talk, you‚Äôre going to learn how to create Machine Learning apps and demos using Streamlit and Gradio, Python libraries for this purpose. Additionally, you‚Äôll see how to share them with the rest of the Open Source ecosystem. Learning to create graphic interfaces for models is extremely useful for sharing with other people interesting them.\nWhat is required to follow it?\nüëâ Basic knowledge of Python\nüëâ Conceptual knowledge of ML\nüëâ A google Colab account\nüëâ A Hugging Face Hub account\nHugging Face organization page for the tutorial: https://huggingface.co/CardiffNLPTutorialHF (anyone can request to join)\nZoom Link: https://cardiff.zoom.us/j/81951311481?pwd=WkJsN09XZ01OM09KaGsvNEx1SVEvUT09\n","date":1648731600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1648731600,"objectID":"7b1489c0023a36eb9e39dda2b3b88de2","permalink":"https://cardiffnlp.github.io/event/2022-03-31/","publishdate":"2022-03-14T00:00:00Z","relpermalink":"/event/2022-03-31/","section":"event","summary":"Talk by: Thomas Simonini (Machine Learning Engineer at HuggingFace)","tags":[],"title":"Hands-on Class with ü§ó: How to Build Machine Learning Collaboratively?","type":"event"},{"authors":["Jose Camacho-Collados"],"categories":null,"content":"","date":1648126800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1648126800,"objectID":"7bb2afc162b1c51ac5221afe03ab3819","permalink":"https://cardiffnlp.github.io/event/2022-03-24/","publishdate":"2022-03-08T23:11:04Z","relpermalink":"/event/2022-03-24/","section":"event","summary":"","tags":[],"title":"[Internal] Cardiff NLP Workshop Organisation","type":"event"},{"authors":["Jose Camacho-Collados"],"categories":null,"content":"","date":1647522e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1647522e3,"objectID":"3407fc1c4b91498ef69e760d8a08557b","permalink":"https://cardiffnlp.github.io/event/2022-03-17/","publishdate":"2022-02-18T23:11:09Z","relpermalink":"/event/2022-03-17/","section":"event","summary":"Talk by Kateryna Krykoniuk (School of English, Communication and Philosophy, Cardiff University)","tags":[],"title":"Seminar: \"Morphological Regularities in English Word Formation: Perspectives for Further Development\"","type":"event"},{"authors":["Fernando Alva-Manchego"],"categories":null,"content":"We are organising a free in-person 2-day Natural Language Processing workshop in Cardiff from June 30 to July 1. We will have invited speakers, tutorials, networking, etc.\nMore information coming soon! For now, safe the date!\n","date":1646870400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1646870400,"objectID":"7c6db52ba4bb6601cb6ca9907bcf6c00","permalink":"https://cardiffnlp.github.io/post/2022-03-10/","publishdate":"2022-03-10T00:00:00Z","relpermalink":"/post/2022-03-10/","section":"post","summary":"We are organising a free in-person 2-day Natural Language Processing workshop in Cardiff from June 30 to July 1. We will have invited speakers, tutorials, networking, etc.\nMore information coming soon!","tags":null,"title":"1st Cardiff NLP Summer Workshop","type":"post"},{"authors":null,"categories":null,"content":"We are organising a free in-person workshop on Natural Language Processing.\nIt will take place from June 30th to July 1st 2022 in Abacws, the brand-new building for the School of Computer Science and the School of Mathematics at Cardiff University.\nTarget Audience\nThe workshop is especially intended to PhD students in UK/Europe, but everyone would be welcome! Workshop Activities\nInvited speakers Tutorials Networking And of course you will have the chance to visit our lovely city while in Cardiff!\nMore details here!\n","date":1646697600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1646697600,"objectID":"52a5ab04b464487ab3cf5384b5c65d9c","permalink":"https://cardiffnlp.github.io/workshop/","publishdate":"2022-03-08T00:00:00Z","relpermalink":"/workshop/","section":"","summary":"We are organising a free in-person workshop on Natural Language Processing.\nIt will take place from June 30th to July 1st 2022 in Abacws, the brand-new building for the School of Computer Science and the School of Mathematics at Cardiff University.","tags":null,"title":"1st Cardiff NLP Summer Workshop","type":"page"},{"authors":["Jose Camacho-Collados"],"categories":null,"content":"","date":1646312400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1646312400,"objectID":"3861ce2c661507150f40cb1a9f28b90f","permalink":"https://cardiffnlp.github.io/event/2022-03-03/","publishdate":"2022-02-18T23:11:04Z","relpermalink":"/event/2022-03-03/","section":"event","summary":"","tags":[],"title":"5-minute Presentations","type":"event"},{"authors":["Jose Camacho-Collados","Luis Espinosa-Anke"],"categories":[],"content":"","date":1645219632,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1645219632,"objectID":"3b2f6728b6ebd745852e6e143ef35c53","permalink":"https://cardiffnlp.github.io/project/hypernymdiscovery/","publishdate":"2022-02-18T21:27:12Z","relpermalink":"/project/hypernymdiscovery/","section":"project","summary":"SemEval-2018 Task 9: Hypernym Discovery","tags":["sharedtask"],"title":"Hypernym Discovery","type":"project"},{"authors":["Asahi Ushio","Jose Camacho-Collados"],"categories":[],"content":"","date":1645219561,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1645219561,"objectID":"f4229f3bbeed4248c1e4642a2ff67a1b","permalink":"https://cardiffnlp.github.io/project/tner/","publishdate":"2022-02-18T21:26:01Z","relpermalink":"/project/tner/","section":"project","summary":"Python Library for Transformer-based Named Entity Recognition","tags":[],"title":"T-NER","type":"project"},{"authors":["Carla P√©rez-Almendros","Luis Espinosa-Anke","Steven Schockaert"],"categories":[],"content":"","date":1645219557,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1645219557,"objectID":"841baf6a04d2aaa8ec1821d237ede1e1","permalink":"https://cardiffnlp.github.io/project/dontpatronizeme/","publishdate":"2022-02-18T21:25:57Z","relpermalink":"/project/dontpatronizeme/","section":"project","summary":"Dataset of patronizing and condescending language towards vulnerable communities","tags":["dataset"],"title":"Don't Patronize Me!","type":"project"},{"authors":["Luis Espinosa-Anke","Jose Camacho-Collados"],"categories":[],"content":"","date":1645219557,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1645219557,"objectID":"7253f3c07c5a158ac93276eaa11a8913","permalink":"https://cardiffnlp.github.io/project/timelms/","publishdate":"2022-02-18T21:25:57Z","relpermalink":"/project/timelms/","section":"project","summary":"Easy access to models continuously trained on social media over regular intervals.","tags":[],"title":"TimeLMs","type":"project"},{"authors":["Jose Camacho-Collados","Luis Espinosa-Anke","Steven Schockaert"],"categories":[],"content":"","date":1645219548,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1645219548,"objectID":"bf8008863287009bfcb9a179c5ede562","permalink":"https://cardiffnlp.github.io/project/relative/","publishdate":"2022-02-18T21:25:48Z","relpermalink":"/project/relative/","section":"project","summary":"Package to learn relation embeddings","tags":["embeddings"],"title":"RELATIVE","type":"project"},{"authors":["Jose Camacho-Collados","Luis Espinosa-Anke","Steven Schockaert"],"categories":[],"content":"","date":1645219544,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1645219544,"objectID":"62b485df6a533e1f540fb6741c65dec4","permalink":"https://cardiffnlp.github.io/project/meemi/","publishdate":"2022-02-18T21:25:44Z","relpermalink":"/project/meemi/","section":"project","summary":"Package to learn cross-lingual word embeddings + pre-trained embeddings","tags":[],"title":"Meemi","type":"project"},{"authors":["Jose Camacho-Collados","Luis Espinosa-Anke"],"categories":[],"content":"","date":1645219538,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1645219538,"objectID":"f151cbc4f1f1b6adf73cb7b781f8893b","permalink":"https://cardiffnlp.github.io/project/tweeteval/","publishdate":"2022-02-18T21:25:38Z","relpermalink":"/project/tweeteval/","section":"project","summary":"Tweet classification unified benchmark + Twitter pre-trained language models","tags":["twitter"],"title":"TweetEval","type":"project"},{"authors":["Luis Espinosa-Anke","Steven Schockaert"],"categories":[],"content":"","date":1645219499,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1645219499,"objectID":"8c801bdaeac76c1d9d15bbaea4373786","permalink":"https://cardiffnlp.github.io/project/seven/","publishdate":"2022-02-18T21:24:59Z","relpermalink":"/project/seven/","section":"project","summary":"Package to learn relation embeddings","tags":["embeddings"],"title":"SeVeN: Semantic Vector Networks","type":"project"},{"authors":["Fernando Alva-Manchego"],"categories":null,"content":"Do you aim to make information more accessible to everyone? I am looking for students to work on different tasks for text adaption (e.g. Text Simplification, Readability Assessment, etc.).\nYou could either apply to one of the School of Computer Science studentships (Deadline 29/04), or be self-funded. Do not hesitate to get in touch if you‚Äôre interested!\n","date":1645142400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1645142400,"objectID":"78f1168eafc205ddd85d7e2d8cfae9a1","permalink":"https://cardiffnlp.github.io/post/2022-02-19/","publishdate":"2022-02-18T00:00:00Z","relpermalink":"/post/2022-02-19/","section":"post","summary":"Do you aim to make information more accessible to everyone? I am looking for students to work on different tasks for text adaption (e.g. Text Simplification, Readability Assessment, etc.).\n","tags":null,"title":"Looking for PhD Students!","type":"post"},{"authors":["Jose Camacho-Collados"],"categories":null,"content":"","date":1645102800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1645102800,"objectID":"774298b0dd87291b4211e867f9007d5e","permalink":"https://cardiffnlp.github.io/event/2022-02-17/","publishdate":"2022-02-18T23:10:57Z","relpermalink":"/event/2022-02-17/","section":"event","summary":"","tags":[],"title":"[Internal] Quarterly Group Meeting","type":"event"},{"authors":["Dimosthenis Antypas"],"categories":null,"content":"","date":1644498e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1644498e3,"objectID":"d4b1fb887fe62f0d0c8cc2e65354602b","permalink":"https://cardiffnlp.github.io/event/2022-02-10/","publishdate":"2022-02-10T00:00:00Z","relpermalink":"/event/2022-02-10/","section":"event","summary":"We will discuss the paper [Sentiment Analysis and Effect of COVID-19 Pandemic using College SubReddit Data](https://arxiv.org/abs/2112.04351).","tags":[],"title":"Reading Group: \"Sentiment Analysis and COVID-19\"","type":"event"},{"authors":["Jose Camacho-Collados"],"categories":null,"content":"","date":1643893200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1643893200,"objectID":"6055889b1e49149dfb58660a26327ee0","permalink":"https://cardiffnlp.github.io/event/2022-02-03/","publishdate":"2022-02-18T23:10:51Z","relpermalink":"/event/2022-02-03/","section":"event","summary":"","tags":[],"title":"[Internal] Staff Meeting","type":"event"},{"authors":["Kiamehr Rezaee"],"categories":null,"content":"","date":1643288400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1643288400,"objectID":"4dc4e8536a7c3999b1e9c3ccdd46cf5b","permalink":"https://cardiffnlp.github.io/event/2022-01-27/","publishdate":"2022-02-18T23:03:08Z","relpermalink":"/event/2022-01-27/","section":"event","summary":"We will discuss the ACL 2020 tutorial [Interpretability and Analysis in Neural NLP](https://aclanthology.org/2020.acl-tutorials.1).","tags":[],"title":"Reading Group: \"Interpretability in NLP\"","type":"event"},{"authors":["Daniel Loureiro","Alƒ±ÃÅpio M√°rio Jorge","Jose Camacho-Collados"],"categories":[],"content":"","date":1640995200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1676388902,"objectID":"acb427c3529bb2e5982c372220b62d11","permalink":"https://cardiffnlp.github.io/publication/loureiro-2022-lmms/","publishdate":"2023-02-14T15:35:01.984387Z","relpermalink":"/publication/loureiro-2022-lmms/","section":"publication","summary":"","tags":[],"title":"LMMS reloaded: Transformer-based sense embeddings for disambiguation and beyond","type":"publication"},{"authors":[],"categories":null,"content":"","date":163845e4,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":163845e4,"objectID":"7fd7f85f2738b2a23487a0da1d87c6a5","permalink":"https://cardiffnlp.github.io/event/2021-12-02/","publishdate":"2022-02-18T23:31:51Z","relpermalink":"/event/2021-12-02/","section":"event","summary":"Talk by Fangyu Liu (Cambridge University)","tags":[],"title":"Seminar: \"Learning Text Representations from Pre-trained Language Models via Contrastive Learning and Self-Distillation\"","type":"event"},{"authors":["Luis Espinosa-Anke","Amit Gajbhiye"],"categories":null,"content":"","date":1637845200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1637845200,"objectID":"a35a704ad700b3658575ee8ae87ab7ea","permalink":"https://cardiffnlp.github.io/event/2021-11-25/","publishdate":"2022-02-18T23:32:06Z","relpermalink":"/event/2021-11-25/","section":"event","summary":"Talks by Elena √Ålvarez Mellado (UNED) and Amit Gajbhiye (Cardiff)","tags":[],"title":"Conference-like Presentations","type":"event"},{"authors":["Asahi Ushio","Federico Liberatore","Jose Camacho-Collados"],"categories":[],"content":"","date":1635724800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1635724800,"objectID":"d0e1ddf60d3d580d61d07bc5c30efc76","permalink":"https://cardiffnlp.github.io/publication/ushio-etal-2021-back/","publishdate":"2022-02-19T16:24:26Z","relpermalink":"/publication/ushio-etal-2021-back/","section":"publication","summary":"Term weighting schemes are widely used in Natural Language Processing and Information Retrieval. In particular, term weighting is the basis for keyword extraction. However, there are relatively few evaluation studies that shed light about the strengths and shortcomings of each weighting scheme. In fact, in most cases researchers and practitioners resort to the well-known tf-idf as default, despite the existence of other suitable alternatives, including graph-based models. In this paper, we perform an exhaustive and large-scale empirical comparison of both statistical and graph-based term weighting methods in the context of keyword extraction. Our analysis reveals some interesting findings such as the advantages of the less-known lexical specificity with respect to tf-idf, or the qualitative differences between statistical and graph-based methods. Finally, based on our findings we discuss and devise some suggestions for practitioners. Source code to reproduce our experimental results, including a keyword extraction library, are available in the following repository: https://github.com/asahi417/kex","tags":[],"title":"Back to the Basics: A Quantitative Analysis of Statistical and Graph-Based Term Weighting Schemes for Keyword Extraction","type":"publication"},{"authors":["Asahi Ushio","Jose Camacho-Collados","Steven Schockaert"],"categories":[],"content":"","date":1635724800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1635724800,"objectID":"d749e4fad538dc7a2c4cde309444c29f","permalink":"https://cardiffnlp.github.io/publication/ushio-etal-2021-distilling/","publishdate":"2022-02-19T16:28:00Z","relpermalink":"/publication/ushio-etal-2021-distilling/","section":"publication","summary":"Pre-trained language models have been found to capture a surprisingly rich amount of lexical knowledge, ranging from commonsense properties of everyday concepts to detailed factual knowledge about named entities. Among others, this makes it possible to distill high-quality word vectors from pre-trained language models. However, it is currently unclear to what extent it is possible to distill relation embeddings, i.e. vectors that characterize the relationship between two words. Such relation embeddings are appealing because they can, in principle, encode relational knowledge in a more fine-grained way than is possible with knowledge graphs. To obtain relation embeddings from a pre-trained language model, we encode word pairs using a (manually or automatically generated) prompt, and we fine-tune the language model such that relationally similar word pairs yield similar output vectors. We find that the resulting relation embeddings are highly competitive on analogy (unsupervised) and relation classification (supervised) benchmarks, even without any task-specific fine-tuning. Source code to reproduce our experimental results and the model checkpoints are available in the following repository: https://github.com/asahi417/relbert","tags":[],"title":"Distilling Relation Embeddings from Pretrained Language Models","type":"publication"},{"authors":["Kiamehr Rezaee","Daniel Loureiro","Jose Camacho-Collados","Mohammad Taher Pilehvar"],"categories":[],"content":"","date":1635724800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1635724800,"objectID":"5e2ecda905d8fb258a07adba234a186f","permalink":"https://cardiffnlp.github.io/publication/rezaee-etal-2021-cross/","publishdate":"2022-02-19T12:51:54Z","relpermalink":"/publication/rezaee-etal-2021-cross/","section":"publication","summary":"In this paper we analyze the extent to which contextualized sense embeddings, i.e., sense embeddings that are computed based on contextualized word embeddings, are transferable across languages.To this end, we compiled a unified cross-lingual benchmark for Word Sense Disambiguation. We then propose two simple strategies to transfer sense-specific knowledge across languages and test them on the benchmark.Experimental results show that this contextualized knowledge can be effectively transferred to similar languages through pre-trained multilingual language models, to the extent that they can out-perform monolingual representations learnednfrom existing language-specific data.","tags":[],"title":"On the Cross-lingual Transferability of Contextualized Sense Embeddings","type":"publication"},{"authors":["Jose Camacho-Collados"],"categories":null,"content":"","date":1635426e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1635426e3,"objectID":"7ece47a47c5d3d17baf02f49e38b3aed","permalink":"https://cardiffnlp.github.io/event/2021-10-28/","publishdate":"2022-02-18T23:32:15Z","relpermalink":"/event/2021-10-28/","section":"event","summary":"","tags":[],"title":"Discussion Panel: \"Teaching in NLP\"","type":"event"},{"authors":["Jose Camacho-Collados"],"categories":null,"content":"","date":1634216400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1634216400,"objectID":"173b52fbcd19da24013a7b65d18ac68f","permalink":"https://cardiffnlp.github.io/event/2021-10-14/","publishdate":"2022-02-18T23:32:20Z","relpermalink":"/event/2021-10-14/","section":"event","summary":"Talk by Valentina Pyatkin (Bar Ilan University)","tags":[],"title":"Seminar: \"A Medley of Event-Based Modality and Role Question Generation\"","type":"event"},{"authors":["Luis Espinosa-Anke"],"categories":null,"content":"","date":1632402e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1632402e3,"objectID":"8b2d270e411c9139515778592a1fc7a8","permalink":"https://cardiffnlp.github.io/event/2021-09-23/","publishdate":"2022-02-18T23:32:31Z","relpermalink":"/event/2021-09-23/","section":"event","summary":"Talk by Marta R. Costa-juss√† (Universitat Polit√®cnica de Catalunya, Barcelona)","tags":[],"title":"Seminar: \"Multilingual Machine Translation with Language-Specific Encoder-Decoders: Translation Quality and Gender Accuracy\"","type":"event"},{"authors":["Jose Camacho-Collados"],"categories":null,"content":"","date":1631797200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1631797200,"objectID":"7a5db7f247226d6101d59a97df986372","permalink":"https://cardiffnlp.github.io/event/2021-09-16/","publishdate":"2022-02-18T23:32:38Z","relpermalink":"/event/2021-09-16/","section":"event","summary":"Talks by Israa Alghanmi, Carla P√©rez-Almendros and Yixiao Wang","tags":[],"title":"Short Presentations by PhD Students","type":"event"},{"authors":["Jose Camacho-Collados"],"categories":null,"content":"","date":1631192400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1631192400,"objectID":"727ba5fad6fd82a5ee2dae2073e9bb02","permalink":"https://cardiffnlp.github.io/event/2021-09-09/","publishdate":"2022-02-18T23:32:45Z","relpermalink":"/event/2021-09-09/","section":"event","summary":"Talk by Thomas Buhrmann and Victoriano Izquierdo","tags":[],"title":"Seminar: \"Graphext, a tool for exploring and modeling complex datasets of structured and unstructured data\"","type":"event"},{"authors":["Asahi Ushio","Luis Espinosa-Anke","Steven Schockaert","Jose Camacho-Collados"],"categories":[],"content":"","date":1627776e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1627776e3,"objectID":"14a1f30b3c01ee92baeb35cafc6b35df","permalink":"https://cardiffnlp.github.io/publication/ushio-etal-2021-bert/","publishdate":"2022-02-19T16:11:22Z","relpermalink":"/publication/ushio-etal-2021-bert/","section":"publication","summary":"Analogies play a central role in human commonsense reasoning. The ability to recognize analogies such as {``}eye is to seeing what ear is to hearing{''}, sometimes referred to as analogical proportions, shape how we structure knowledge and understand language. Surprisingly, however, the task of identifying such analogies has not yet received much attention in the language model era. In this paper, we analyze the capabilities of transformer-based language models on this unsupervised task, using benchmarks obtained from educational settings, as well as more commonly used datasets. We find that off-the-shelf language models can identify analogies to a certain extent, but struggle with abstract and complex relations, and results are highly sensitive to model architecture and hyperparameters. Overall the best results were obtained with GPT-2 and RoBERTa, while configurations using BERT were not able to outperform word embedding models. Our results raise important questions for future work about how, and to what extent, pre-trained language models capture knowledge about abstract semantic relations.","tags":[],"title":"BERT is to NLP what AlexNet is to CV: Can Pre-Trained Language Models Identify Analogies?","type":"publication"},{"authors":["Dimosthenis Antypas","Jose Camacho-Collados","Alun Preece","David Rogers"],"categories":[],"content":"","date":1627776e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1627776e3,"objectID":"d596bb9506ce644cbd2337feaeeb43ed","permalink":"https://cardiffnlp.github.io/publication/antypas-etal-2021-covid/","publishdate":"2022-02-19T16:16:54Z","relpermalink":"/publication/antypas-etal-2021-covid/","section":"publication","summary":"Social media is often used by individuals and organisations as a platform to spread misinformation. With the recent coronavirus pandemic we have seen a surge of misinformation on Twitter, posing a danger to public health. In this paper, we compile a large COVID-19 Twitter misinformation corpus and perform an analysis to discover patterns with respect to vocabulary usage. Among others, our analysis reveals that the variety of topics and vocabulary usage are considerably more limited and negative in tweets related to misinformation than in randomly extracted tweets. In addition to our qualitative analysis, our experimental results show that a simple linear model based only on lexical features is effective in identifying misinformation-related tweets (with accuracy over 80%), providing evidence to the fact that the vocabulary used in misinformation largely differs from generic tweets.","tags":[],"title":"COVID-19 and Misinformation: A Large-Scale Lexical Analysis on Twitter","type":"publication"},{"authors":["Yixiao Wang","Zied Bouraoui","Luis Espinosa-Anke","Steven Schockaert"],"categories":[],"content":"","date":1627776e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1627776e3,"objectID":"99c4be77bcba65595fb24369be6b8631","permalink":"https://cardiffnlp.github.io/publication/wang-etal-2021-deriving/","publishdate":"2022-02-19T23:09:26Z","relpermalink":"/publication/wang-etal-2021-deriving/","section":"publication","summary":"One of the long-standing challenges in lexical semantics consists in learning representations of words which reflect their semantic properties. The remarkable success of word embeddings for this purpose suggests that high-quality representations can be obtained by summarizing the sentence contexts of word mentions. In this paper, we propose a method for learning word representations that follows this basic strategy, but differs from standard word embeddings in two important ways. First, we take advantage of contextualized language models (CLMs) rather than bags of word vectors to encode contexts. Second, rather than learning a word vector directly, we use a topic model to partition the contexts in which words appear, and then learn different topic-specific vectors for each word. Finally, we use a task-specific supervision signal to make a soft selection of the resulting vectors. We show that this simple strategy leads to high-quality word vectors, which are more predictive of semantic properties than word embeddings and existing CLM-based strategies.","tags":[],"title":"Deriving Word Vectors from Contextualized Language Models using Topic-Aware Mention Selection","type":"publication"},{"authors":["Israa Alghanmi","Luis Espinosa-Anke","Steven Schockaert"],"categories":[],"content":"","date":1627776e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1627776e3,"objectID":"e840e6d05b89c97fa6e9a319aa39108c","permalink":"https://cardiffnlp.github.io/publication/alghanmi-etal-2021-probing/","publishdate":"2022-02-19T23:18:12Z","relpermalink":"/publication/alghanmi-etal-2021-probing/","section":"publication","summary":"Pre-trained language models such as ClinicalBERT have achieved impressive results on tasks such as medical Natural Language Inference. At first glance, this may suggest that these models are able to perform medical reasoning tasks, such as mapping symptoms to diseases. However, we find that standard benchmarks such as MedNLI contain relatively few examples that require such forms of reasoning. To better understand the medical reasoning capabilities of existing language models, in this paper we introduce DisKnE, a new benchmark for Disease Knowledge Evaluation. To construct this benchmark, we annotated each positive MedNLI example with the types of medical reasoning that are needed. We then created negative examples by corrupting these positive examples in an adversarial way. Furthermore, we define training-test splits per disease, ensuring that no knowledge about test diseases can be learned from the training data, and we canonicalize the formulation of the hypotheses to avoid the presence of artefacts. This leads to a number of binary classification problems, one for each type of reasoning and each disease. When analysing pre-trained models for the clinical/biomedical domain on the proposed benchmark, we find that their performance drops considerably","tags":[],"title":"Probing Pre-Trained Language Models for Disease Knowledge","type":"publication"},{"authors":["Daniel Loureiro","Kiamehr Rezaee","Mohammad Taher Pilehvar","Jose Camacho-Collados"],"categories":[],"content":"","date":1622505600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1622505600,"objectID":"6904a3144e99c982e64b8125c61e1aef","permalink":"https://cardiffnlp.github.io/publication/loureiro-etal-2021-analysis/","publishdate":"2022-02-19T16:32:00Z","relpermalink":"/publication/loureiro-etal-2021-analysis/","section":"publication","summary":"Abstract Transformer-based language models have taken many fields in NLP by storm. BERT and its derivatives dominate most of the existing evaluation benchmarks, including those for Word Sense Disambiguation (WSD), thanks to their ability in capturing context-sensitive semantic nuances. However, there is still little knowledge about their capabilities and potential limitations in encoding and recovering word senses. In this article, we provide an in-depth quantitative and qualitative analysis of the celebrated BERT model with respect to lexical ambiguity. One of the main conclusions of our analysis is that BERT can accurately capture high-level sense distinctions, even when a limited number of examples is available for each word sense. Our analysis also reveals that in some cases language models come close to solving coarse-grained noun disambiguation under ideal conditions in terms of availability of training data and computing resources. However, this scenario rarely occurs in real-world settings and, hence, many practical challenges remain even in the coarse-grained setting. We also perform an in-depth comparison of the two main language model-based WSD strategies, namely, fine-tuning and feature extraction, finding that the latter approach is more robust with respect to sense bias and it can better exploit limited available training data. In fact, the simple feature extraction strategy of averaging contextualized embeddings proves robust even using only three training sentences per word sense, with minimal improvements obtained by increasing the size of this training data.","tags":[],"title":"Analysis and Evaluation of Language Models for Word Sense Disambiguation","type":"publication"},{"authors":["Luis Espinosa-Anke","Joan Codina-Filba","Leo Wanner"],"categories":[],"content":"","date":1617235200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1617235200,"objectID":"369a27b2f716bc1495d1a073060a2504","permalink":"https://cardiffnlp.github.io/publication/espinosa-anke-etal-2021-evaluating/","publishdate":"2022-02-19T23:12:41Z","relpermalink":"/publication/espinosa-anke-etal-2021-evaluating/","section":"publication","summary":"Lexical collocations are idiosyncratic combinations of two syntactically bound lexical items (e.g., ''heavy rain'' or ''take a step''). Understanding their degree of compositionality and idiosyncrasy, as well their underlying semantics, is crucial for language learners, lexicographers and downstream NLP applications. In this paper, we perform an exhaustive analysis of current language models for collocation understanding. We first construct a dataset of apparitions of lexical collocations in context, categorized into 17 representative semantic categories. Then, we perform two experiments: (1) unsupervised collocate retrieval using BERT, and (2) supervised collocation classification in context. We find that most models perform well in distinguishing light verb constructions, especially if the collocation's first argument acts as subject, but often fail to distinguish, first, different syntactic structures within the same semantic category, and second, fine-grained semantic categories which restrict the use of small sets of valid collocates for a given base.","tags":[],"title":"Evaluating Language Models for the Retrieval and Categorization of Lexical Collocations","type":"publication"},{"authors":["Asahi Ushio","Jose Camacho-Collados"],"categories":[],"content":"","date":1617235200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1617235200,"objectID":"d33df3018091d159ce362b0a4acdb8c6","permalink":"https://cardiffnlp.github.io/publication/ushio-camacho-collados-2021-ner/","publishdate":"2022-02-19T12:47:03Z","relpermalink":"/publication/ushio-camacho-collados-2021-ner/","section":"publication","summary":"Language model (LM) pretraining has led to consistent improvements in many NLP downstream tasks, including named entity recognition (NER). In this paper, we present T-NER (Transformer-based Named Entity Recognition), a Python library for NER LM finetuning. In addition to its practical utility, T-NER facilitates the study and investigation of the cross-domain and cross-lingual generalization ability of LMs finetuned on NER. Our library also provides a web app where users can get model predictions interactively for arbitrary text, which facilitates qualitative model evaluation for non-expert programmers. We show the potential of the library by compiling nine public NER datasets into a unified format and evaluating the cross-domain and cross- lingual performance across the datasets. The results from our initial experiments show that in-domain performance is generally competitive across datasets. However, cross-domain generalization is challenging even with a large pretrained LM, which has nevertheless capacity to learn domain-specific features if fine- tuned on a combined dataset. To facilitate future research, we also release all our LM checkpoints via the Hugging Face model hub.","tags":[],"title":"T-NER: An All-Round Python Library for Transformer-based Named Entity Recognition","type":"publication"},{"authors":["Anna Breit","Artem Revenko","Kiamehr Rezaee","Mohammad Taher Pilehvar","Jose Camacho-Collados"],"categories":[],"content":"","date":1617235200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1617235200,"objectID":"aa415b0a15de488185be1d1392e122d8","permalink":"https://cardiffnlp.github.io/publication/breit-etal-2021-wic/","publishdate":"2022-02-19T12:17:57Z","relpermalink":"/publication/breit-etal-2021-wic/","section":"publication","summary":"We present WiC-TSV, a new multi-domain evaluation benchmark for Word Sense Disambiguation. More specifically, we introduce a framework for Target Sense Verification of Words in Context which grounds its uniqueness in the formulation as binary classification task thus being independent of external sense inventories, and the coverage of various domains. This makes the dataset highly flexible for the evaluation of a diverse set of models and systems in and across domains. WiC-TSV provides three different evaluation settings, depending on the input signals provided to the model. We set baseline performance on the dataset using state-of-the-art language models. Experimental results show that even though these models can perform decently on the task, there remains a gap between machine and human performance, especially in out-of-domain settings. WiC-TSV data is available at https://competitions.codalab.org/competitions/23683.","tags":[],"title":"WiC-TSV: An Evaluation Benchmark for Target Sense Verification of Words in Context","type":"publication"},{"authors":["Rana Alshaikh","Zied Bouraoui","Shelan Jeawak","Steven Schockaert"],"categories":[],"content":"","date":1606780800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1606780800,"objectID":"17019b4482eb2753e1a112c3580e7627","permalink":"https://cardiffnlp.github.io/publication/alshaikh-etal-2020-mixture/","publishdate":"2022-02-19T23:26:58Z","relpermalink":"/publication/alshaikh-etal-2020-mixture/","section":"publication","summary":"Various methods have already been proposed for learning entity embeddings from text descriptions. Such embeddings are commonly used for inferring properties of entities, for recommendation and entity-oriented search, and for injecting background knowledge into neural architectures, among others. Entity embeddings essentially serve as a compact encoding of a similarity relation, but similarity is an inherently multi-faceted notion. By representing entities as single vectors, existing methods leave it to downstream applications to identify these different facets, and to select the most relevant ones. In this paper, we propose a model that instead learns several vectors for each entity, each of which intuitively captures a different aspect of the considered domain. We use a mixture-of-experts formulation to jointly learn these facet-specific embeddings. The individual entity embeddings are learned using a variant of the GloVe model, which has the advantage that we can easily identify which properties are modelled well in which of the learned embeddings. This is exploited by an associated gating network, which uses pre-trained word vectors to encourage the properties that are modelled by a given embedding to be semantically coherent, i.e. to encourage each of the individual embeddings to capture a meaningful facet.","tags":[],"title":"A Mixture-of-Experts Model for Learning Multi-Facet Entity Embeddings","type":"publication"},{"authors":["Shelan Jeawak","Luis Espinosa-Anke","Steven Schockaert"],"categories":[],"content":"","date":1606780800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1606780800,"objectID":"35ff70d35295581262f80b81261f7e0d","permalink":"https://cardiffnlp.github.io/publication/jeawak-etal-2020-cardiff/","publishdate":"2022-02-19T23:38:11Z","relpermalink":"/publication/jeawak-etal-2020-cardiff/","section":"publication","summary":"We describe the system submitted to SemEval-2020 Task 6, Subtask 1. The aim of this subtask is to predict whether a given sentence contains a definition or not. Unsurprisingly, we found that strong results can be achieved by fine-tuning a pre-trained BERT language model. In this paper, we analyze the performance of this strategy. Among others, we show that results can be improved by using a two-step fine-tuning process, in which the BERT model is first fine-tuned on the full training set, and then further specialized towards a target domain.","tags":[],"title":"Cardiff University at SemEval-2020 Task 6: Fine-tuning BERT for Domain-Specific Definition Classification","type":"publication"},{"authors":["Beatriz Fisas","Luis Espinosa-Anke","Joan Codina-Filb√°","Leo Wanner"],"categories":[],"content":"","date":1606780800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1606780800,"objectID":"84ae31f3c21867dc802cfbf5e104b44e","permalink":"https://cardiffnlp.github.io/publication/fisas-etal-2020-collfren/","publishdate":"2022-02-19T23:44:58Z","relpermalink":"/publication/fisas-etal-2020-collfren/","section":"publication","summary":"Collocations in the sense of idiosyncratic lexical co-occurrences of two syntactically bound words traditionally pose a challenge to language learners and many Natural Language Processing (NLP) applications alike. Reliable ground truth (i.e., ideally manually compiled) resources are thus of high value. We present a manually compiled bilingual English{--}French collocation resource with 7,480 collocations in English and 6,733 in French. Each collocation is enriched with information that facilitates its downstream exploitation in NLP tasks such as machine translation, word sense disambiguation, natural language generation, relation classification, and so forth. Our proposed enrichment covers: the semantic category of the collocation (its lexical function), its vector space representation (for each individual word as well as their joint collocation embedding), a subcategorization pattern of both its elements, as well as their corresponding BabelNet id, and finally, indices of their occurrences in large scale reference corpora.","tags":[],"title":"CollFrEn: Rich Bilingual English--French Collocation Resource","type":"publication"},{"authors":["Mireia Roig Mirapeix","Luis Espinosa-Anke","Jose Camacho-Collados"],"categories":[],"content":"","date":1606780800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1606780800,"objectID":"933bf822a7ff25f394290379b8b2bfcd","permalink":"https://cardiffnlp.github.io/publication/roig-mirapeix-etal-2020-definition/","publishdate":"2022-02-19T22:44:36Z","relpermalink":"/publication/roig-mirapeix-etal-2020-definition/","section":"publication","summary":"Textual definitions constitute a fundamental source of knowledge when seeking the meaning of words, and they are the cornerstone of lexical resources like glossaries, dictionaries, encyclopedia or thesauri. In this paper, we present an in-depth analytical study on the main features relevant to the task of definition extraction. Our main goal is to study whether linguistic structures from canonical (the Aristotelian or genus et differentia model) can be leveraged to retrieve definitions from corpora in different domains of knowledge and textual genres alike. To this end, we develop a simple linear classifier and analyze the contribution of several (sets of) linguistic features. Finally, as a result of our experiments, we also shed light on the particularities of existing benchmarks as well as the most challenging aspects of the task.","tags":[],"title":"Definition Extraction Feature Analysis: From Canonical to Naturally-Occurring Definitions","type":"publication"},{"authors":["Carla P√©rez-Almendros","Luis Espinosa-Anke","Steven Schockaert"],"categories":[],"content":"","date":1606780800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1606780800,"objectID":"b890e336b26fffb4cae243b6c1649aab","permalink":"https://cardiffnlp.github.io/publication/perez-almendros-etal-2020-dont/","publishdate":"2022-02-19T23:35:07Z","relpermalink":"/publication/perez-almendros-etal-2020-dont/","section":"publication","summary":"In this paper, we introduce a new annotated dataset which is aimed at supporting the development of NLP models to identify and categorize language that is patronizing or condescending towards vulnerable communities (e.g. refugees, homeless people, poor families). While the prevalence of such language in the general media has long been shown to have harmful effects, it differs from other types of harmful language, in that it is generally used unconsciously and with good intentions. We furthermore believe that the often subtle nature of patronizing and condescending language (PCL) presents an interesting technical challenge for the NLP community. Our analysis of the proposed dataset shows that identifying PCL is hard for standard NLP models, with language models such as BERT achieving the best results.","tags":[],"title":"Don't Patronize Me! An Annotated Dataset with Patronizing and Condescending Language towards Vulnerable Communities","type":"publication"},{"authors":["Jose Camacho-Collados","Mohammad Taher Pilehvar"],"categories":[],"content":"","date":1606780800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1606780800,"objectID":"7d0895052a8159e8f039a15a709040b5","permalink":"https://cardiffnlp.github.io/publication/camacho-collados-pilehvar-2020-embeddings/","publishdate":"2022-02-19T20:14:20Z","relpermalink":"/publication/camacho-collados-pilehvar-2020-embeddings/","section":"publication","summary":"Embeddings have been one of the most important topics of interest in NLP for the past decade. Representing knowledge through a low-dimensional vector which is easily integrable in modern machine learning models has played a central role in the development of the field. Embedding techniques initially focused on words but the attention soon started to shift to other forms. This tutorial will provide a high-level synthesis of the main embedding techniques in NLP, in the broad sense. We will start by conventional word embeddings (e.g., Word2Vec and GloVe) and then move to other types of embeddings, such as sense-specific and graph alternatives. We will finalize with an overview of the trending contextualized representations (e.g., ELMo and BERT) and explain their potential and impact in NLP.","tags":[],"title":"Embeddings in Natural Language Processing","type":"publication"},{"authors":["Aleks Edwards","Jose Camacho-Collados","H√©l√®ne de Ribaupierre","Alun Preece"],"categories":[],"content":"","date":1606780800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1606780800,"objectID":"0a681d3585f6c52c6f3021f65e1ab33d","permalink":"https://cardiffnlp.github.io/publication/edwards-etal-2020-go/","publishdate":"2022-02-19T20:03:57Z","relpermalink":"/publication/edwards-etal-2020-go/","section":"publication","summary":"Pre-trained language models provide the foundations for state-of-the-art performance across a wide range of natural language processing tasks, including text classification. However, most classification datasets assume a large amount labeled data, which is commonly not the case in practical settings. In particular, in this paper we compare the performance of a light-weight linear classifier based on word embeddings, i.e., fastText (Joulin et al., 2017), versus a pre-trained language model, i.e., BERT (Devlin et al., 2019), across a wide range of datasets and classification tasks. In general, results show the importance of domain-specific unlabeled data, both in the form of word embeddings or language models. As for the comparison, BERT outperforms all baselines in standard datasets with large training sets. However, in settings with small training datasets a simple method like fastText coupled with domain-specific word embeddings performs equally well or better than BERT, even when pre-trained on domain-specific data.","tags":[],"title":"Go Simple and Pre-Train on Domain-Specific Corpora: On the Role of Training Data for Text Classification","type":"publication"},{"authors":["David Owen","Jose Camacho-Collados","Luis Espinosa-Anke"],"categories":[],"content":"","date":1606780800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1606780800,"objectID":"e5ba29e1bb2a533d067daf334ce6baf1","permalink":"https://cardiffnlp.github.io/publication/owen-etal-2020-towards/","publishdate":"2022-02-19T22:48:35Z","relpermalink":"/publication/owen-etal-2020-towards/","section":"publication","summary":"Depression and anxiety are psychiatric disorders that are observed in many areas of everyday life. For example, these disorders manifest themselves somewhat frequently in texts written by nondiagnosed users in social media. However, detecting users with these conditions is not a straightforward task as they may not explicitly talk about their mental state, and if they do, contextual cues such as immediacy must be taken into account. When available, linguistic flags pointing to probable anxiety or depression could be used by medical experts to write better guidelines and treatments. In this paper, we develop a dataset designed to foster research in depression and anxiety detection in Twitter, framing the detection task as a binary tweet classification problem. We then apply state-of-the-art classification models to this dataset, providing a competitive set of baselines alongside qualitative error analysis. Our results show that language models perform reasonably well, and better than more traditional baselines. Nonetheless, there is clear room for improvement, particularly with unbalanced training sets and in cases where seemingly obvious linguistic cues (keywords) are used counter-intuitively.","tags":[],"title":"Towards Preemptive Detection of Depression and Anxiety in Twitter","type":"publication"},{"authors":["Israa Alghanmi","Luis Espinosa-Anke","Steven Schockaert"],"categories":[],"content":"","date":1604188800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1604188800,"objectID":"b737fb81b032169ecf204e5dcd455d7a","permalink":"https://cardiffnlp.github.io/publication/alghanmi-etal-2020-combining/","publishdate":"2022-02-19T23:41:36Z","relpermalink":"/publication/alghanmi-etal-2020-combining/","section":"publication","summary":"Pre-trained neural language models (LMs) have achieved impressive results in various natural language processing tasks, across different languages. Surprisingly, this extends to the social media genre, despite the fact that social media often has very different characteristics from the language that LMs have seen during training. A particularly striking example is the performance of AraBERT, an LM for the Arabic language, which is successful in categorizing social media posts in Arabic dialects, despite only having been trained on Modern Standard Arabic. Our hypothesis in this paper is that the performance of LMs for social media can nonetheless be improved by incorporating static word vectors that have been specifically trained on social media. We show that a simple method for incorporating such word vectors is indeed successful in several Arabic and English benchmarks. Curiously, however, we also find that similar improvements are possible with word vectors that have been trained on traditional text sources (e.g. Wikipedia).","tags":[],"title":"Combining BERT with Static Word Embeddings for Categorizing Social Media","type":"publication"},{"authors":["Daniel Loureiro","Jose Camacho-Collados"],"categories":[],"content":"","date":1604188800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1604188800,"objectID":"30c72b0d17df3bc188d258fae0d022a5","permalink":"https://cardiffnlp.github.io/publication/loureiro-camacho-collados-2020-dont/","publishdate":"2022-02-19T22:52:11Z","relpermalink":"/publication/loureiro-camacho-collados-2020-dont/","section":"publication","summary":"State-of-the-art methods for Word Sense Disambiguation (WSD) combine two different features: the power of pre-trained language models and a propagation method to extend the coverage of such models. This propagation is needed as current sense-annotated corpora lack coverage of many instances in the underlying sense inventory (usually WordNet). At the same time, unambiguous words make for a large portion of all words in WordNet, while being poorly covered in existing sense-annotated corpora. In this paper, we propose a simple method to provide annotations for most unambiguous words in a large corpus. We introduce the UWA (Unambiguous Word Annotations) dataset and show how a state-of-the-art propagation-based model can use it to extend the coverage and quality of its word sense embeddings by a significant margin, improving on its original results on WSD.","tags":[],"title":"Don't Neglect the Obvious: On the Role of Unambiguous Words in Word Sense Disambiguation","type":"publication"},{"authors":["Francesco Barbieri","Jose Camacho-Collados","Luis Espinosa-Anke","Leonardo Neves"],"categories":[],"content":"","date":1604188800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1604188800,"objectID":"e3af374b91460b882a62d33a6bb8b156","permalink":"https://cardiffnlp.github.io/publication/barbieri-etal-2020-tweeteval/","publishdate":"2022-02-19T22:41:19Z","relpermalink":"/publication/barbieri-etal-2020-tweeteval/","section":"publication","summary":"The experimental landscape in natural language processing for social media is too fragmented. Each year, new shared tasks and datasets are proposed, ranging from classics like sentiment analysis to irony detection or emoji prediction. Therefore, it is unclear what the current state of the art is, as there is no standardized evaluation protocol, neither a strong set of baselines trained on such domain-specific data. In this paper, we propose a new evaluation framework (TweetEval) consisting of seven heterogeneous Twitter-specific classification tasks. We also provide a strong set of baselines as starting point, and compare different language modeling pre-training strategies. Our initial experiments show the effectiveness of starting off with existing pre-trained generic language models, and continue training them on Twitter corpora.","tags":[],"title":"TweetEval: Unified Benchmark and Comparative Evaluation for Tweet Classification","type":"publication"},{"authors":["Hsiao-Yu Chiang","Jose Camacho-Collados","Zachary Pardos"],"categories":[],"content":"","date":1604188800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1604188800,"objectID":"bb93c1af2125f14e3808cac6ad5ea6c3","permalink":"https://cardiffnlp.github.io/publication/chiang-etal-2020-understanding/","publishdate":"2022-02-19T22:58:35Z","relpermalink":"/publication/chiang-etal-2020-understanding/","section":"publication","summary":"Semantic relations are core to how humans understand and express concepts in the real world using language. Recently, there has been a thread of research aimed at modeling these relations by learning vector representations from text corpora. Most of these approaches focus strictly on leveraging the co-occurrences of relationship word pairs within sentences. In this paper, we investigate the hypothesis that examples of a lexical relation in a corpus are fundamental to a neural word embedding{'}s ability to complete analogies involving the relation. Our experiments, in which we remove all known examples of a relation from training corpora, show only marginal degradation in analogy completion performance involving the removed relation. This finding enhances our understanding of neural word embeddings, showing that co-occurrence information of a particular semantic relation is not the main source of their structural regularity.","tags":[],"title":"Understanding the Source of Semantic Regularities in Word Embeddings","type":"publication"},{"authors":["Alessandro Raganato","Tommaso Pasini","Jose Camacho-Collados","Mohammad Taher Pilehvar"],"categories":[],"content":"","date":1604188800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1604188800,"objectID":"07c75c470352618859a1f9b2d49cc0e0","permalink":"https://cardiffnlp.github.io/publication/raganato-etal-2020-xl/","publishdate":"2022-02-19T22:55:06Z","relpermalink":"/publication/raganato-etal-2020-xl/","section":"publication","summary":"The ability to correctly model distinct meanings of a word is crucial for the effectiveness of semantic representation techniques. However, most existing evaluation benchmarks for assessing this criterion are tied to sense inventories (usually WordNet), restricting their usage to a small subset of knowledge-based representation techniques. The Word-in-Context dataset (WiC) addresses the dependence on sense inventories by reformulating the standard disambiguation task as a binary classification problem; but, it is limited to the English language. We put forward a large multilingual benchmark, XL-WiC, featuring gold standards in 12 new languages from varied language families and with different degrees of resource availability, opening room for evaluation scenarios such as zero-shot cross-lingual transfer. We perform a series of experiments to determine the reliability of the datasets and to set performance baselines for several recent contextualized multilingual models. Experimental results show that even when no tagged instances are available for a target language, models trained solely on the English data can attain competitive performance in the task of distinguishing different meanings of a word, even for distant languages. XL-WiC is available at https://pilehvar.github.io/xlwic/.","tags":[],"title":"XL-WiC: A Multilingual Benchmark for Evaluating Semantic Contextualization","type":"publication"},{"authors":["Tomoki Ito","Jose Camacho-Collados","Hiroki Sakaji","Steven Schockaert"],"categories":[],"content":"","date":1593561600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1593561600,"objectID":"ad69d0c17db0a63dff3b4be58e785468","permalink":"https://cardiffnlp.github.io/publication/ito-etal-2020-learning/","publishdate":"2022-02-19T23:01:53Z","relpermalink":"/publication/ito-etal-2020-learning/","section":"publication","summary":"Organizing companies by industry segment (e.g. artificial intelligence, healthcare or fintech) is useful for analyzing stock market performance and for designing theme base investment funds, among others. Current practice is to manually assign companies to sectors or industries from a small predefined list, which has two key limitations. First, due to the manual effort involved, this strategy is only feasible for relatively mainstream industry segments, and can thus not easily be used for niche or emerging topics. Second, the use of hard label assignments ignores the fact that different companies will be more or less exposed to a particular segment. To address these limitations, we propose to learn vector representations of companies based on their annual reports. The key challenge is to distill the relevant information from these reports for characterizing their industries, since annual reports also contain a lot of information which is not relevant for our purpose. To this end, we introduce a multi-task learning strategy, which is based on fine-tuning the BERT language model on (i) existing sector labels and (ii) stock market performance. Experiments in both English and Japanese demonstrate the usefulness of this strategy","tags":[],"title":"Learning Company Embeddings from Annual Reports for Fine-grained Industry Characterization","type":"publication"},{"authors":["Tommaso Pasini","Jose Camacho-Collados"],"categories":[],"content":"","date":1588291200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1588291200,"objectID":"a42ca067cee568f971c252930e572080","permalink":"https://cardiffnlp.github.io/publication/pasini-camacho-collados-2020-short/","publishdate":"2022-02-19T20:23:25Z","relpermalink":"/publication/pasini-camacho-collados-2020-short/","section":"publication","summary":"Large sense-annotated datasets are increasingly necessary for training deep supervised systems in Word Sense Disambiguation. However, gathering high-quality sense-annotated data for as many instances as possible is a laborious and expensive task. This has led to the proliferation of automatic and semi-automatic methods for overcoming the so-called knowledge-acquisition bottleneck. In this short survey we present an overview of sense-annotated corpora, annotated either manually- or (semi)automatically, that are currently available for different languages and featuring distinct lexical resources as inventory of senses, i.e. WordNet, Wikipedia, BabelNet. Furthermore, we provide the reader with general statistics of each dataset and an analysis of their specific features.","tags":[],"title":"A Short Survey on Sense-Annotated Corpora","type":"publication"},{"authors":["Yerai Doval","Jose Camacho-Collados","Luis Espinosa-Anke","Steven Schockaert"],"categories":[],"content":"","date":1588291200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1588291200,"objectID":"4d4c33b6001197bb34ce1568a0d20781","permalink":"https://cardiffnlp.github.io/publication/doval-etal-2020-robustness/","publishdate":"2022-02-19T20:19:43Z","relpermalink":"/publication/doval-etal-2020-robustness/","section":"publication","summary":"Cross-lingual word embeddings are vector representations of words in different languages where words with similar meaning are represented by similar vectors, regardless of the language. Recent developments which construct these embeddings by aligning monolingual spaces have shown that accurate alignments can be obtained with little or no supervision, which usually comes in the form of bilingual dictionaries. However, the focus has been on a particular controlled scenario for evaluation, and there is no strong evidence on how current state-of-the-art systems would fare with noisy text or for language pairs with major linguistic differences. In this paper we present an extensive evaluation over multiple cross-lingual embedding models, analyzing their strengths and limitations with respect to different variables such as target language, training corpora and amount of supervision. Our conclusions put in doubt the view that high-quality cross-lingual embeddings can always be learned without much supervision.","tags":[],"title":"On the Robustness of Unsupervised and Semi-supervised Cross-lingual Word Embedding Learning","type":"publication"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"f26b5133c34eec1aa0a09390a36c2ade","permalink":"https://cardiffnlp.github.io/admin/config.yml","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/admin/config.yml","section":"","summary":"","tags":null,"title":"","type":"wowchemycms"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"c1d17ff2b20dca0ad6653a3161942b64","permalink":"https://cardiffnlp.github.io/people/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/people/","section":"","summary":"","tags":null,"title":"","type":"widget_page"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"f1d044c0738ab9f19347f15c290a71a1","permalink":"https://cardiffnlp.github.io/research/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/research/","section":"","summary":"","tags":null,"title":"","type":"widget_page"}]